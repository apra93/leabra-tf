{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Running a Basic Model on Combigen\n",
    "\n",
    "In this notebook we're going to just run the combigen task designed in nb 0.1 on some more modern models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 18 2019 20:32:44 \n",
      "\n",
      "CPython 3.6.8\n",
      "IPython 7.2.0\n",
      "\n",
      "numpy 1.15.4\n",
      "matplotlib 3.0.2\n",
      "seaborn 0.9.0\n",
      "tensorflow 1.10.0\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-45-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 9e066d8690c6a5afc03915dc3eaf756cda317f85\n",
      "Git branch : resnet\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and packages. Add more as necessary.\n",
    "%watermark -v -n -m -g -b -t -p numpy,matplotlib,seaborn,tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `matplotlib` in one of the more `jupyter`-friendly [rich-output modes](https://ipython.readthedocs.io/en/stable/interactive/plotting.html). Some options (that may or may not have worked) are `inline`, `notebook`, and `gtk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static imports that shouldn't necessarily change throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import logging\n",
    "\n",
    "# Third party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task script\n",
    "%aimport leabratf.tasks.combinatorics.combigen\n",
    "import leabratf.tasks.combinatorics.combigen as cbg\n",
    "# Visualization for the task\n",
    "%aimport leabratf.visualization.combigen_heatmap\n",
    "import leabratf.visualization.combigen_heatmap as cbhm\n",
    "# Utility functions\n",
    "%aimport leabratf.utils\n",
    "from leabratf.utils import setup_logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set [seaborn defaults](https://seaborn.pydata.org/generated/seaborn.set.html) for matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the logger configuration to something more useful than baseline. Creates log files for the different log levels in the `logs` directory.\n",
    "\n",
    "See `logging.yml` for the exact logging configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run base logger setup\n",
    "setup_logging()\n",
    "# Define a logger object\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Combigen Task\n",
    "\n",
    "Now that the task has been put together from nb 0.1, let's import the functionified version of it and start prepping for running the model.\n",
    "\n",
    "First let's refresh our memory on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:32:51 apra-xps13 leabratf.utils[3514] WARNING First argument passed is not of type `np.ndarray`. Skipping reshape operation.\n",
      "2019-02-18 20:32:51 apra-xps13 leabratf.utils[3514] WARNING First argument passed is not of type `np.ndarray`. Skipping reshape operation.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbhm.visualize_combigen(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it works as expected, lets move back to setting up the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O'Reily BP Model\n",
    "\n",
    "Before working with anything close to state of the art (SOTA), a good place to start is with the backpropagation model that O'Reily used in his paper. It's described as a fully connected network with 100 hidden units, so let's put all that into a hyper-parameter variable.\n",
    "\n",
    "Note: Instead of dictionaries to hold config-type data, I'm using `pdict`s from the [pstar](https://github.com/iansf/pstar) repo as mentioned in [this](https://danijar.com/patterns-for-fast-prototyping-with-tensorflow/) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdicts allow for attribute dictionary setting among other things\n",
    "from pstar import pdict\n",
    "# for the checkpoint path\n",
    "from leabratf.constants import DIR_MODELS\n",
    "\n",
    "hyper_params = pdict()\n",
    "\n",
    "# Task parameters - see the 0.1 for the experimental design\n",
    "hyper_params.combigen_dims = 2\n",
    "hyper_params.combigen_size = 5\n",
    "# Stack number is currently not implemented, but will be for future analyses\n",
    "# hyper_params.combigen_stack = 4\n",
    "hyper_params.n_train = 100\n",
    "hyper_params.n_test = 10000\n",
    "\n",
    "# Network parameters - see paper description\n",
    "hyper_params.layer_size = 100\n",
    "hyper_params.output_size = hyper_params[['combigen_size', 'combigen_dims']]\n",
    "\n",
    "# Training parameters\n",
    "hyper_params.learning_rate = 0.001\n",
    "hyper_params.batch_size = 1 \n",
    "hyper_params.epochs = 100\n",
    "\n",
    "# Experiment Parameters\n",
    "hyper_params.save_weights = True\n",
    "hyper_params.validation_iters = 1000\n",
    "\n",
    "hyper_params.checkpoint_path = str(DIR_MODELS / 'checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put together the dataset object that will be fed into the model. First generate the master list of data to be used for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape y: (10100, 5, 2) \n",
      "Shape X: (10100, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "y = cbg.generate_labels(\n",
    "    n_samples = hyper_params.n_train + hyper_params.n_test,\n",
    "    size = hyper_params['combigen_size'],\n",
    "    dims = hyper_params['combigen_dims'])\n",
    "X = cbg.inverse_transform(y)\n",
    "# Quick sanity check\n",
    "assert X.shape[0] == y.shape[0]\n",
    "\n",
    "# Lets print some quick info\n",
    "print('Shape y: {0} \\nShape X: {1}'.format(y.shape, X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then let's put it in a `dataset` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input fn\n",
    "def input_fn(mode, params):\n",
    "    n_samples = params.n_train if mode==tf.estimator.ModeKeys.EVAL else params.n_test\n",
    "    \n",
    "    y = cbg.generate_labels(n_samples=n_samples,\n",
    "                            size=params['combigen_size'],\n",
    "                            dims=params['combigen_dims'])\n",
    "    X = cbg.inverse_transform(y)\n",
    "    # Quick sanity check\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.batch(params['batch_size'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start putting together the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_obp(input_tensor, mode, hyper_params):\n",
    "    \"\"\"Function that generates the the O'Reily backpropagation model.\"\"\"\n",
    "    model = pdict()\n",
    "    with tf.variable_scope(\"OBPDenseNet\") as scope:\n",
    "        # Reuse the weights if we're evaling\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            scope.reuse_variables()\n",
    "        # Reshape the data accordingly\n",
    "        x = tf.reshape(tensor=input_tensor, shape=[-1, *hyper_params['output_size']], name='input')\n",
    "        # Single hidden layer\n",
    "        model.logits = tf.layers.dense(x, units=hyper_params['layer_size'])\n",
    "        model.probs = tf.nn.softmax(logits=model.logits, name='probs')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loss(model, labels, mode, hyper_params):\n",
    "    \"\"\"Function that returns the loss of a model on the labels.\"\"\"\n",
    "    metrics = pdict()\n",
    "    \n",
    "    y = tf.reshape(labels, [-1, *hyper_params['output_size']], name='labels')\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=model.logits,\n",
    "        labels=y,\n",
    "    ))\n",
    "    loss_name = str(mode) + '/loss'\n",
    "    tf.summary.scalar(loss_name, loss_op)\n",
    "    metrics.loss_name = loss_op\n",
    "    \n",
    "    return loss_op, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now put them together along with an optimizer to create `model_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    # Create the model\n",
    "    model = create_model_obp(features, mode, params)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=model)\n",
    "    \n",
    "    # Create the loss operation\n",
    "    loss, metrics = create_loss(model, labels, mode, params)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "    \n",
    "    # Define the optimizer\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        with tf.variable_scope(\"optimizer\"):\n",
    "            # Define a training operation\n",
    "            train_op = tf.train.GradientDescentOptimizer(\n",
    "                learning_rate=params['learning_rate']).minimize(loss)\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    raise RuntimeError('Invalid mode entered, {})'.format(mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpduqp2a1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] WARNING Using temporary folder as model directory: /tmp/tmpduqp2a1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpduqp2a1d', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff2a85b9080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Using config: {'_model_dir': '/tmp/tmpduqp2a1d', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff2a85b9080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:34 apra-xps13 tensorflow[3514] INFO Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpduqp2a1d/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 20:39:35 apra-xps13 tensorflow[3514] INFO Saving checkpoints for 0 into /tmp/tmpduqp2a1d/model.ckpt.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 25 values, but the requested shape requires a multiple of 10\n\t [[Node: OBPDenseNet/input = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorGetNext, labels/shape)]]\n\nCaused by op 'OBPDenseNet/input', defined at:\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-2c2e39843215>\", line 8, in <module>\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 451, in train_and_evaluate\n    return executor.run()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 590, in run\n    return self.run_local()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 691, in run_local\n    saving_listeners=saving_listeners)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1170, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1133, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-17-b3f96322f167>\", line 3, in model_fn\n    model = create_model_obp(features, mode, params)\n  File \"<ipython-input-12-8c80f3711f2b>\", line 9, in create_model_obp\n    x = tf.reshape(tensor=input_tensor, shape=[-1, *hyper_params['output_size']], name='input')\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6199, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 25 values, but the requested shape requires a multiple of 10\n\t [[Node: OBPDenseNet/input = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorGetNext, labels/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 25 values, but the requested shape requires a multiple of 10\n\t [[Node: OBPDenseNet/input = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorGetNext, labels/shape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2c2e39843215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0meval_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvalSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    449\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    589\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1171\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1172\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1449\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1452\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    581\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1060\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1205\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 25 values, but the requested shape requires a multiple of 10\n\t [[Node: OBPDenseNet/input = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorGetNext, labels/shape)]]\n\nCaused by op 'OBPDenseNet/input', defined at:\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-2c2e39843215>\", line 8, in <module>\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 451, in train_and_evaluate\n    return executor.run()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 590, in run\n    return self.run_local()\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 691, in run_local\n    saving_listeners=saving_listeners)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1170, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1133, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-17-b3f96322f167>\", line 3, in model_fn\n    model = create_model_obp(features, mode, params)\n  File \"<ipython-input-12-8c80f3711f2b>\", line 9, in create_model_obp\n    x = tf.reshape(tensor=input_tensor, shape=[-1, *hyper_params['output_size']], name='input')\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6199, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/apra/miniconda3/envs/leabratf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 25 values, but the requested shape requires a multiple of 10\n\t [[Node: OBPDenseNet/input = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorGetNext, labels/shape)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = tf.estimator.RunConfig()\n",
    "estimator = tf.estimator.Estimator(model_fn, params=hyper_params)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=lambda:input_fn(tf.estimator.ModeKeys.TRAIN, hyper_params))\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=lambda:input_fn(tf.estimator.ModeKeys.EVAL, hyper_params))\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params.output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So let's just confirm that `tensorflow` is happy with the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "Various hints for working on `jupyter notebooks`. Should probably be removed when a notebook is completed.\n",
    "\n",
    "General stuff:\n",
    "- To make logging even lazier, set `print = logger.info`, and then `print` away!\n",
    "- The `!` can be used to run shell commands from within the notebook (ex. `!which conda`)\n",
    "- Use `assert` liberally - this isn't a script and it's very readable.\n",
    "\n",
    "Cheatsheets:\n",
    "- [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
