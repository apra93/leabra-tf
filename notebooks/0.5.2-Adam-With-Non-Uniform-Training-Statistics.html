

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>0.5.2 Adam with Non-Uniform Training Statistics &mdash; Leabra Tensorflow 0+untagged.52.ge1fecd8 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="0.6 Hebbian Learning" href="0.6-Hebbian-Learning.html" />
    <link rel="prev" title="0.5.1 Adam with Non-Uniform Task Statistics" href="0.5.1-Adam-With-Non-Uniform-Task-Statistics.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Leabra Tensorflow
          

          
          </a>

          
            
            
              <div class="version">
                0+untagged.52.ge1fecd8
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../release_schedule.html">Release Schedule</a></li>
</ul>
<p class="caption"><span class="caption-text">Tasks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../combinatorics.html">Combinatorial Generalizaton and Interactivity</a></li>
</ul>
<p class="caption"><span class="caption-text">Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../visualization.html">Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">Utility Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tfutils.html">Tensorflow Utility Functions</a></li>
</ul>
<p class="caption"><span class="caption-text">Notebooks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="0.0-Notebook-Template.html">0.0 Leabra-tf Notebook Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1-Designing-the-Combigen-Task.html">0.1 Implementing the Combinatorial Generalization Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.1-Combigen-All-True-Bug-Fix.html">0.1.1 Combigen All-True Bug Fix</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.2-Combigen-Stacks.html">0.1.2 Combigen Stacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.3-Specifying-the-Number-of-Lines.html">0.1.3 Specifying the Number of Lines</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.4-Selectable-Line-Statistics.html">0.1.4 Selectable Line Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.2-Running-a-Basic-Model-on-Combigen.html">0.2 Running a Basic Model on Combigen</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.2.1-Iterating-the-BP-Model-on-GPUs.html">0.2.1 Iterating the BP Model on GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.3-BP-Model-in-Tensorflow.html">0.3 BP Model in Tensorflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.3.1-Comparing-Accuracy-Metrics.html">0.3.1 Comparing Accuracy Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.3.2-Model-Checkpoints.html">0.3.2 Model Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.3.3-GPU-Performance-Metrics.html">0.3.3 GPU Performance Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.4-Exploring-Different-Learning-Rates.html">0.4 Exploring Different Learning Rates</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.4.1-Exploring-Different-Optimizers.html">0.4.1 Exploring Different Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.5-Adam-Optimizer-Learning-Rate-Tuning-and-Dropout.html">0.5 Adam Optimizer Learning Rate Tuning and Dropout</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.5.1-Adam-With-Non-Uniform-Task-Statistics.html">0.5.1 Adam with Non-Uniform Task Statistics</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">0.5.2 Adam with Non-Uniform Training Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Boilerplate">Boilerplate</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Jupyter-Extensions">Jupyter Extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Imports">Imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Initial-Setup">Initial Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Default-Configuration">Default Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Datasets">Datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Background">Background</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#The-Combigen-Task">The Combigen Task</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Adam-Optimizer-Performance-Thus-Far">Adam Optimizer Performance Thus Far</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Setting-Up-the-Graph">Setting Up the Graph</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Make-the-Different-Datasets">Make the Different Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#TF-Variables">TF Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Model-and-Metrics">Model and Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Varying-the-Optimizer">Varying the Optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#New-Session-Function">New Session Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Defining-the-Training-Function">Defining the Training Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Defining-The-Training-Routine">Defining The Training Routine</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Adam-Optimizer-with-the-Different-Training-Sets">Adam Optimizer with the Different Training Sets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Getting-the-Metrics">Getting the Metrics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Plotting-Results">Plotting Results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Comparing-Datasets">Comparing Datasets</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Debugging-the-Increasing-Validation-Loss">Debugging the Increasing Validation Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Rerunning-the-Analysis">Rerunning the Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#New-Plots">New Plots</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Extra-Epochs-for-SGD">Extra Epochs for SGD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#New-Plot-with-2500-Epochs-for-SGD">New Plot with 2500 Epochs for SGD</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="0.6-Hebbian-Learning.html">0.6 Hebbian Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.7-Replicating-Results-with-the-Updated-Task.html">0.7 Replicating Results with the Updated Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.7.1-Managing-Technical-Debt.html">0.7.1 Managing Technical Debt</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.8-Hierarchical-Learning.html">0.8 Hierarchical Learning</a></li>
</ul>
<p class="caption"><span class="caption-text">Project Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://apra93.github.io/leabra-tf/">Home</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apra93/leabra-tf/">Github</a></li>
<li class="toctree-l1"><a class="reference external" href="https://travis-ci.org/apra93/leabra-tf">Travis CI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://codecov.io/gh/apra93/leabra-tf">Codecov</a></li>
<li class="toctree-l1"><a class="reference external" href="https://app.codacy.com/project/apra93/leabra-tf/dashboard">Codacy</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Leabra Tensorflow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>0.5.2 Adam with Non-Uniform Training Statistics</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/0.5.2-Adam-With-Non-Uniform-Training-Statistics.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="0.5.2-Adam-with-Non-Uniform-Training-Statistics">
<h1>0.5.2 Adam with Non-Uniform Training Statistics<a class="headerlink" href="#0.5.2-Adam-with-Non-Uniform-Training-Statistics" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Boilerplate">
<h2>Boilerplate<a class="headerlink" href="#Boilerplate" title="Permalink to this headline">¶</a></h2>
<p>The following subsections are largely boilerplate code, so skip around as needed.</p>
<div class="section" id="Jupyter-Extensions">
<h3>Jupyter Extensions<a class="headerlink" href="#Jupyter-Extensions" title="Permalink to this headline">¶</a></h3>
<p>Load <a class="reference external" href="https://github.com/rasbt/watermark">watermark</a> to see the state of the machine and environment that’s running the notebook. To make sense of the options, take a look at the <a class="reference external" href="https://github.com/rasbt/watermark#usage">usage</a> section of the readme.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Load `watermark` extension</span>
<span class="o">%</span><span class="k">load_ext</span> watermark
<span class="c1"># Display the status of the machine and packages. Add more as necessary.</span>
<span class="o">%</span><span class="k">watermark</span> -v -n -m -g -b -t -p numpy,matplotlib,seaborn,tensorflow
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Wed May 22 2019 11:18:22

CPython 3.6.8
IPython 7.3.0

numpy 1.16.2
matplotlib 3.0.3
seaborn 0.9.0
tensorflow 1.12.0

compiler   : GCC 7.3.0
system     : Linux
release    : 4.4.0-130-generic
machine    : x86_64
processor  : x86_64
CPU cores  : 12
interpreter: 64bit
Git hash   : 810f976398276557f16e1a3950c0699c4cefcbbb
Git branch : master
</pre></div></div>
</div>
<p>Load <a class="reference external" href="https://ipython.org/ipython-doc/3/config/extensions/autoreload.html">autoreload</a> which will always reload modules marked with <code class="docutils literal notranslate"><span class="pre">%aimport</span></code>.</p>
<p>This behavior can be inverted by running <code class="docutils literal notranslate"><span class="pre">autoreload</span> <span class="pre">2</span></code> which will set everything to be auto-reloaded <em>except</em> for modules marked with <code class="docutils literal notranslate"><span class="pre">%aimport</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Load `autoreload` extension</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="c1"># Set autoreload behavior</span>
<span class="o">%</span><span class="k">autoreload</span> 1
</pre></div>
</div>
</div>
<p>Load <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> in one of the more <code class="docutils literal notranslate"><span class="pre">jupyter</span></code>-friendly <a class="reference external" href="https://ipython.readthedocs.io/en/stable/interactive/plotting.html">rich-output modes</a>. Some options (that may or may not have worked) are <code class="docutils literal notranslate"><span class="pre">inline</span></code>, <code class="docutils literal notranslate"><span class="pre">notebook</span></code>, and <code class="docutils literal notranslate"><span class="pre">gtk</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Set the matplotlib mode.</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="section" id="Imports">
<h3>Imports<a class="headerlink" href="#Imports" title="Permalink to this headline">¶</a></h3>
<p>Static imports that shouldn’t necessarily change throughout the notebook.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Standard library imports</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="k">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="k">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="k">import</span> <span class="n">pprint</span>

<span class="c1"># Third party</span>
<span class="kn">import</span> <span class="nn">IPython</span> <span class="k">as</span> <span class="nn">ipy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">pstar</span> <span class="k">import</span> <span class="n">pdict</span>
</pre></div>
</div>
</div>
<p>Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Task script</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.tasks.combinatorics.combigen
<span class="kn">import</span> <span class="nn">leabratf.tasks.combinatorics.combigen</span> <span class="k">as</span> <span class="nn">cg</span>
<span class="c1"># Visualization for the task</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.visualization.combigen_heatmap
<span class="kn">import</span> <span class="nn">leabratf.visualization.combigen_heatmap</span> <span class="k">as</span> <span class="nn">cgh</span>
<span class="c1"># Metrics visulaization</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.visualization.metrics
<span class="kn">import</span> <span class="nn">leabratf.visualization.metrics</span> <span class="k">as</span> <span class="nn">plt_metrics</span>
<span class="c1"># Utility functions</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.utils
<span class="kn">from</span> <span class="nn">leabratf.utils</span> <span class="k">import</span> <span class="n">setup_logging</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.constants
<span class="kn">from</span> <span class="nn">leabratf.constants</span> <span class="k">import</span> <span class="n">DIR_DATA_PROC</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.tasks.combinatorics.default_configuration
<span class="kn">from</span> <span class="nn">leabratf.tasks.combinatorics.default_configuration</span> <span class="k">import</span> <span class="n">default_config</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Initial-Setup">
<h3>Initial Setup<a class="headerlink" href="#Initial-Setup" title="Permalink to this headline">¶</a></h3>
<p>Set <a class="reference external" href="https://seaborn.pydata.org/generated/seaborn.set.html">seaborn defaults</a> for matplotlib.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Set up the logger configuration to something more useful than baseline. Creates log files for the different log levels in the <code class="docutils literal notranslate"><span class="pre">logs</span></code> directory.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">logging.yml</span></code> for the exact logging configuration.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Run base logger setup</span>
<span class="n">setup_logging</span><span class="p">()</span>
<span class="c1"># Define a logger object</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;leabratf&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Default-Configuration">
<h3>Default Configuration<a class="headerlink" href="#Default-Configuration" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Define the base experiment configuration</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">default_config</span><span class="p">()</span>
<span class="c1"># Overwrite any configuration values here</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/device:CPU:0&#39;</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[188]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Define a config dict constructor based on the cfg above</span>
<span class="n">default_nb_config</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">default_config</span><span class="p">(</span><span class="o">**</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
<span class="c1"># Testing set config</span>
<span class="n">testing_set_config</span> <span class="o">=</span> <span class="n">default_nb_config</span><span class="p">(</span><span class="n">_name</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">testing_set_config</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">testing_set_config</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;_config&#39;: True,
 &#39;_name&#39;: &#39;test&#39;,
 &#39;batch_size&#39;: 500,
 &#39;dims&#39;: 2,
 &#39;dir_checkpoints&#39;: PosixPath(&#39;/home/abdullah_rashed/work/projects/leabra-tf/models/checkpoints&#39;),
 &#39;dir_tensorboard&#39;: PosixPath(&#39;/home/abdullah_rashed/work/projects/leabra-tf/data/tensorboard&#39;),
 &#39;epochs&#39;: 500,
 &#39;line_stats&#39;: [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]],
 &#39;lr&#39;: 0.01,
 &#39;n_epochs_acc&#39;: 25,
 &#39;n_hidden_1&#39;: 100,
 &#39;n_inputs&#39;: 100,
 &#39;n_lines&#39;: 2,
 &#39;n_models&#39;: 10,
 &#39;n_outputs&#39;: 40,
 &#39;n_samples&#39;: 500,
 &#39;n_test&#39;: 500,
 &#39;n_train&#39;: 100,
 &#39;n_updates&#39;: 2,
 &#39;n_val&#39;: 50,
 &#39;optimizer&#39;: &#39;sgd&#39;,
 &#39;size&#39;: 5,
 &#39;slots&#39;: 4,
 &#39;tf_device&#39;: &#39;/device:CPU:0&#39;}
&lt;class &#39;pstar.pstar.pdict&#39;&gt;
</pre></div></div>
</div>
<div class="section" id="Datasets">
<h4>Datasets<a class="headerlink" href="#Datasets" title="Permalink to this headline">¶</a></h4>
<p>Here we will introduce new line sampling statistics</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[189]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Uniform, same as before. Not actually needed but here for</span>
<span class="c1"># comparative purposes</span>
<span class="n">uniform</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>
<span class="c1"># One element is twice as likely to occur as any other element</span>
<span class="n">one_elem</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>
<span class="c1"># Two elements are twice as likely to occur as any other element</span>
<span class="n">two_elem</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]]</span>
<span class="c1"># Half the elements are twice as likely to occur as the other half</span>
<span class="n">half_elem</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>

<span class="c1"># String names for the stats</span>
<span class="n">train_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;train_1e&#39;</span><span class="p">,</span> <span class="s1">&#39;train_2e&#39;</span><span class="p">,</span> <span class="s1">&#39;train_he&#39;</span><span class="p">,</span> <span class="s1">&#39;train_uni&#39;</span><span class="p">]</span>
<span class="n">stats</span> <span class="o">=</span> <span class="p">[</span><span class="n">one_elem</span><span class="p">,</span> <span class="n">two_elem</span><span class="p">,</span> <span class="n">half_elem</span><span class="p">,</span> <span class="n">uniform</span><span class="p">]</span>
<span class="c1"># Arrange these into a dictionary</span>
<span class="n">stats_dict</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">({</span><span class="n">name</span> <span class="p">:</span> <span class="n">stat</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">stat</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">train_names</span><span class="p">,</span> <span class="n">stats</span><span class="p">)})</span>

<span class="c1"># Training Set experiment configurations</span>
<span class="n">training_set_configs</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">({</span><span class="n">name</span> <span class="p">:</span> <span class="n">default_nb_config</span><span class="p">(</span><span class="n">line_stats</span><span class="o">=</span><span class="n">stat</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                                      <span class="n">n_samples</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_samples</span><span class="p">,</span>
                                                      <span class="n">_name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">stats_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[190]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">np_datasets</span><span class="p">(</span><span class="n">configs</span><span class="p">):</span>
    <span class="n">datasets</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">()</span>
    <span class="n">inner_config</span> <span class="o">=</span> <span class="n">configs</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">inner_config</span><span class="p">,</span> <span class="s1">&#39;_config&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">inner_config</span><span class="o">.</span><span class="n">_config</span><span class="p">:</span>
        <span class="n">inner_config</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">({</span><span class="n">inner_config</span><span class="o">.</span><span class="n">_name</span> <span class="p">:</span> <span class="n">inner_config</span><span class="p">})</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">exp_cfg</span> <span class="ow">in</span> <span class="n">inner_config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Generate the datasets</span>
        <span class="n">y_data</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">generate_labels</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">exp_cfg</span><span class="o">.</span><span class="n">n_samples</span><span class="p">,</span>
                                    <span class="n">slots</span><span class="o">=</span><span class="n">exp_cfg</span><span class="o">.</span><span class="n">slots</span><span class="p">,</span>
                                    <span class="n">size</span><span class="o">=</span><span class="n">exp_cfg</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
                                    <span class="n">dims</span><span class="o">=</span><span class="n">exp_cfg</span><span class="o">.</span><span class="n">dims</span><span class="p">,</span>
                                    <span class="n">n_lines</span><span class="o">=</span><span class="n">exp_cfg</span><span class="o">.</span><span class="n">n_lines</span><span class="p">,</span>
                                    <span class="n">line_stats</span><span class="o">=</span><span class="n">exp_cfg</span><span class="o">.</span><span class="n">line_stats</span><span class="p">)</span>
        <span class="n">x_data</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_data</span><span class="p">)</span>
        <span class="c1"># Add them to the datasets pdict</span>
        <span class="n">datasets</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">datasets</span>

<span class="c1"># Single pdict of x,y datasets</span>
<span class="n">dataset_configs</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">({</span><span class="n">testing_set_config</span><span class="o">.</span><span class="n">_name</span><span class="p">:</span> <span class="n">testing_set_config</span><span class="p">})</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
    <span class="n">training_set_configs</span><span class="p">)</span>
<span class="n">np_datasets</span> <span class="o">=</span> <span class="n">np_datasets</span><span class="p">(</span><span class="n">dataset_configs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="Background">
<h2>Background<a class="headerlink" href="#Background" title="Permalink to this headline">¶</a></h2>
<p>This section goes over some of the background information for the notebook using results from previous notebooks. This first section shows the task as always, but then will also go over the previous training curves.</p>
<div class="section" id="The-Combigen-Task">
<h3>The Combigen Task<a class="headerlink" href="#The-Combigen-Task" title="Permalink to this headline">¶</a></h3>
<p>Quickly remind ourselves what the task looks like before diving in.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[191]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cgh</span><span class="o">.</span><span class="n">visualize_combigen</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_27_0.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_27_0.png" />
</div>
</div>
</div>
<div class="section" id="Adam-Optimizer-Performance-Thus-Far">
<h3>Adam Optimizer Performance Thus Far<a class="headerlink" href="#Adam-Optimizer-Performance-Thus-Far" title="Permalink to this headline">¶</a></h3>
<p>In <a class="reference internal" href="0.7-Replicating-Results-with-the-Updated-Task.html"><span class="doc">nb-0.7</span></a> we showed that Adam Optimizer still performed better than the standard model.</p>
</div>
</div>
<div class="section" id="Setting-Up-the-Graph">
<h2>Setting Up the Graph<a class="headerlink" href="#Setting-Up-the-Graph" title="Permalink to this headline">¶</a></h2>
<p>This next section will define the computational graph that will be used to generate the metrics down below. It is largely code copied from nb-0.3, so skip around as needed.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[192]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Cleanup any residual nodes</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="Make-the-Different-Datasets">
<h3>Make the Different Datasets<a class="headerlink" href="#Make-the-Different-Datasets" title="Permalink to this headline">¶</a></h3>
<p>Define the various <code class="docutils literal notranslate"><span class="pre">tf.Dataset</span></code>s that will be used including the ones with the different statistics.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[193]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">make_tf_datasets</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">configs</span><span class="p">,</span> <span class="n">init_ops</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># The first step of the setup is that each of the datasets (training, validation, and</span>
    <span class="c1"># testing) are turned into their own `Dataset` objects.</span>
    <span class="n">tf_datasets</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">(</span>
        <span class="p">{</span><span class="n">name</span> <span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
            <span class="n">datasets</span><span class="p">[</span><span class="n">name</span><span class="p">])</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">configs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
         <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">()})</span>

    <span class="c1"># Next, let&#39;s define the iterators for each of the datasets, and then add their</span>
    <span class="c1"># initializations to the `init_ops` list.</span>
    <span class="c1"># Training iterator</span>
    <span class="n">iterators</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">({</span><span class="n">name</span> <span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span>
                      <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tf_datasets</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>

    <span class="c1"># Add the initiatlizations to the init opts</span>
    <span class="n">init_ops</span> <span class="o">=</span> <span class="n">init_ops</span> <span class="ow">or</span> <span class="p">[]</span>
    <span class="n">init_ops</span> <span class="o">+=</span> <span class="p">[</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span> <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="n">iterators</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>

    <span class="n">first_dataset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tf_datasets</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">output_types</span><span class="p">,</span> <span class="n">output_shapes</span> <span class="o">=</span> <span class="n">first_dataset</span><span class="o">.</span><span class="n">output_types</span><span class="p">,</span> <span class="n">first_dataset</span><span class="o">.</span><span class="n">output_shapes</span>

    <span class="c1"># And finally, the interesting part. Rather than creating separate next elements for</span>
    <span class="c1"># the model, the `tf.data` API has a string handler iterator so we can contextually</span>
    <span class="c1"># switch the active `Dataset` object, resulting in different values being used for `x`</span>
    <span class="c1"># and `y`.</span>

    <span class="c1"># The way this is done is by defining a `tf.placeholder` variable, which is used</span>
    <span class="c1"># first to create a string handler iterator, and later to hold the dataset-indicating</span>
    <span class="c1"># string handle. The string handler iterator is what then changes the values of `x` and</span>
    <span class="c1"># `y`, naturally also supplying them using the `get_next` method.</span>
    <span class="c1"># The placeholder variable of type string</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[])</span>

    <span class="c1"># Iterator from string handle</span>
    <span class="n">handle_iterator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="o">.</span><span class="n">from_string_handle</span><span class="p">(</span>
        <span class="n">handle</span><span class="p">,</span> <span class="n">output_types</span><span class="p">,</span> <span class="n">output_shapes</span><span class="p">)</span>

    <span class="c1"># x and y that will be used in the graph</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">handle_iterator</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">iterators</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">init_ops</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="TF-Variables">
<h3>TF Variables<a class="headerlink" href="#TF-Variables" title="Permalink to this headline">¶</a></h3>
<p>Straight forward section where we define the weights and biases. One thing to note is that the weights are initialized using the <code class="docutils literal notranslate"><span class="pre">tf.contrib.layers.xavier_initializer</span></code>.</p>
<p>Additionally, create an empty list that will contain the initialization operations to be performed at the start of a session.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[194]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Weights and biases</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;h1&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;w_h1&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_hidden_1</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()),</span>
    <span class="s1">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;w_out&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_hidden_1</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()),</span>
<span class="p">}</span>
<span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;b1&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;b_1&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_hidden_1</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()),</span>
    <span class="s1">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;b_out&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()),</span>
<span class="p">}</span>

<span class="n">init_ops</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Model-and-Metrics">
<h3>Model and Metrics<a class="headerlink" href="#Model-and-Metrics" title="Permalink to this headline">¶</a></h3>
<p>The architecture is the same as previous notebooks. See <code class="docutils literal notranslate"><span class="pre">nb-0.3</span></code> for more details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[195]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">oreilly_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
    <span class="c1"># Reshape for hidden layer</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">])</span>
    <span class="c1"># Single hidden layer</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;h1&#39;</span><span class="p">]),</span> <span class="n">biases</span><span class="p">[</span><span class="s1">&#39;b1&#39;</span><span class="p">]))</span>
    <span class="c1"># Output layer</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;out&#39;</span><span class="p">]),</span> <span class="n">biases</span><span class="p">[</span><span class="s1">&#39;out&#39;</span><span class="p">])</span>
    <span class="c1"># Reshape for labels</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">slots</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dims</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[196]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">tf_device</span><span class="p">):</span>
    <span class="c1"># Get the relevant dataset nodes</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">iterators</span><span class="p">,</span> <span class="n">handler</span><span class="p">,</span> <span class="n">init_ops</span> <span class="o">=</span> <span class="n">make_tf_datasets</span><span class="p">(</span>
        <span class="n">np_datasets</span><span class="p">,</span> <span class="n">dataset_configs</span><span class="p">,</span> <span class="n">init_ops</span><span class="p">)</span>

    <span class="c1"># Build the model</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">oreilly_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
    <span class="c1"># Ensure y is cast to the same type as logits</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># We will keep this in for now</span>
    <span class="c1"># Define alpha as placeholder variable</span>
    <span class="n">alpha_ph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[])</span>

    <span class="c1"># Define loss and optimizer</span>
    <span class="n">loss_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span>

    <span class="c1"># Define some intermediate nodes</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">rounded_predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    <span class="n">equal_labels_and_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">rounded_predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="c1"># O&#39;Reilly Accuracy</span>
    <span class="n">axis_acc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">equal_labels_and_preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">slot_acc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">axis_acc</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">sample_acc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">slot_acc</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Elemental Accuracy</span>
    <span class="n">el_acc_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">equal_labels_and_preds</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="c1"># Axis Accuracy</span>
    <span class="n">axis_acc_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">axis_acc</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="c1"># Slot Accuracy</span>
    <span class="n">slot_acc_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">slot_acc</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="c1"># Sample Accuracy</span>
    <span class="n">sample_acc_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">sample_acc</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="c1"># metric ops</span>
    <span class="n">met_op_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="s1">&#39;el_acc&#39;</span><span class="p">,</span> <span class="s1">&#39;ax_acc&#39;</span><span class="p">,</span> <span class="s1">&#39;sl_acc&#39;</span><span class="p">,</span> <span class="s1">&#39;sm_acc&#39;</span><span class="p">]</span>
    <span class="n">met_ops</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_op</span><span class="p">,</span> <span class="n">el_acc_op</span><span class="p">,</span> <span class="n">axis_acc_op</span><span class="p">,</span> <span class="n">slot_acc_op</span><span class="p">,</span> <span class="n">sample_acc_op</span><span class="p">]</span>
    <span class="c1"># Put them in a dict</span>
    <span class="n">met_op_dict</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">({</span><span class="n">name</span> <span class="p">:</span> <span class="n">op</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">met_op_names</span><span class="p">,</span> <span class="n">met_ops</span><span class="p">)})</span>

    <span class="c1"># Generic metrics dict</span>
    <span class="n">generic_metrics_dict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="p">:</span> <span class="n">pdict</span><span class="p">({</span><span class="n">name</span> <span class="p">:</span> <span class="p">[]</span>
                                           <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">met_op_names</span><span class="o">+</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]})</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Varying-the-Optimizer">
<h3>Varying the Optimizer<a class="headerlink" href="#Varying-the-Optimizer" title="Permalink to this headline">¶</a></h3>
<p>Let’s create several different training operations.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[199]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">tf_device</span><span class="p">):</span>
    <span class="c1"># Adam</span>
    <span class="n">train_op_adam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">alpha_ph</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss_op</span><span class="p">)</span>
    <span class="c1"># Adadelta</span>
    <span class="n">train_op_adadelta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdadeltaOptimizer</span><span class="p">(</span><span class="n">alpha_ph</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss_op</span><span class="p">)</span>
    <span class="c1"># RMSProp</span>
    <span class="n">train_op_rmsprop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">RMSPropOptimizer</span><span class="p">(</span><span class="n">alpha_ph</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss_op</span><span class="p">)</span>
    <span class="c1"># SGD</span>
    <span class="n">train_op_sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">alpha_ph</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss_op</span><span class="p">)</span>

<span class="c1"># And now add these to a dictionary</span>
<span class="n">optimizer_dict</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">({</span>
    <span class="s1">&#39;Adam&#39;</span> <span class="p">:</span> <span class="n">train_op_adam</span><span class="p">,</span>
    <span class="s1">&#39;Adadelta&#39;</span> <span class="p">:</span> <span class="n">train_op_adadelta</span><span class="p">,</span>
    <span class="s1">&#39;RMSProp&#39;</span> <span class="p">:</span> <span class="n">train_op_rmsprop</span><span class="p">,</span>
    <span class="s1">&#39;sgd&#39;</span> <span class="p">:</span> <span class="n">train_op_sgd</span><span class="p">,</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="New-Session-Function">
<h3>New Session Function<a class="headerlink" href="#New-Session-Function" title="Permalink to this headline">¶</a></h3>
<p>In the event that we do not want to immediately close sessions, we won’t be using the context handler but will still need to grab new sessions as necessary. So let’s quickly write a function that will properly run <code class="docutils literal notranslate"><span class="pre">sess.close()</span></code> if a previous session exists and then return a new <code class="docutils literal notranslate"><span class="pre">tf.Session</span></code> instance.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[200]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">new_session</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="c1"># Try to close the globally defined session if it isn&#39;t already</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sess</span><span class="o">.</span><span class="n">_closed</span><span class="p">:</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="c1"># If it doesn&#39;t exist, then just pass</span>
    <span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="c1"># Return the new instance</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Defining-the-Training-Function">
<h3>Defining the Training Function<a class="headerlink" href="#Defining-the-Training-Function" title="Permalink to this headline">¶</a></h3>
<p>Let’s define a function that runs the training routine and accepts the number of epochs as the inputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[214]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">train_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span>
                <span class="n">train_op</span><span class="o">=</span><span class="n">optimizer_dict</span><span class="p">[</span><span class="n">cfg</span><span class="o">.</span><span class="n">optimizer</span><span class="p">],</span>
                <span class="n">init_ops</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">n_train</span><span class="o">=</span><span class="n">training_set_configs</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">n_train</span><span class="p">,</span>
                <span class="n">training_set_name</span><span class="o">=</span><span class="s1">&#39;train_uni&#39;</span><span class="p">,</span>
                <span class="n">testing_set_name</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span>
                <span class="n">n_val</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">log_level</span> <span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">info</span> <span class="k">if</span> <span class="n">verbose</span> <span class="k">else</span> <span class="n">logger</span><span class="o">.</span><span class="n">debug</span>
    <span class="n">log_level</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Beginning training using learning rate, </span><span class="si">{lr}</span><span class="s1">, </span><span class="si">{train_op.name}</span><span class="s1"> &#39;</span>
              <span class="n">f</span><span class="s1">&#39;training routine, for </span><span class="si">{epochs}</span><span class="s1"> epochs, on </span><span class="si">{training_set_name}</span><span class="s1"> &#39;</span>
              <span class="n">f</span><span class="s1">&#39;training set. Testing using </span><span class="si">{testing_set_name}</span><span class="s1"> dataset.&#39;</span><span class="p">)</span>
    <span class="c1"># Ensure this is an int</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
    <span class="c1"># Dict with the various metrics we care about while training</span>
    <span class="n">training_metrics</span> <span class="o">=</span> <span class="n">generic_metrics_dict</span><span class="p">()</span>

    <span class="c1"># Run the initialization ops</span>
    <span class="n">init_ops</span> <span class="o">=</span> <span class="n">init_ops</span> <span class="ow">or</span> <span class="p">[]</span>
    <span class="n">init_ops</span> <span class="o">+=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">(),</span>
                 <span class="n">tf</span><span class="o">.</span><span class="n">local_variables_initializer</span><span class="p">()]</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_ops</span><span class="p">)</span>

    <span class="c1"># Define training and validation handlers</span>
    <span class="n">handles</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">({</span><span class="n">name</span> <span class="p">:</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">iterators</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">string_handle</span><span class="p">())</span>
                    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">iterators</span><span class="o">.</span><span class="n">keys</span><span class="p">()})</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train</span><span class="p">):</span>
            <span class="c1"># Training op and compute metrics</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">train_op</span><span class="p">,</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">alpha_ph</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span> <span class="n">handler</span><span class="p">:</span> <span class="n">handles</span><span class="p">[</span><span class="n">training_set_name</span><span class="p">]})</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">n_val</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">met_ops</span><span class="p">,</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">handler</span><span class="p">:</span> <span class="n">handles</span><span class="p">[</span><span class="n">testing_set_name</span><span class="p">]})</span>
            <span class="c1"># Record</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">met_op_names</span><span class="p">,</span> <span class="n">metrics</span><span class="p">):</span>
                <span class="n">training_metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>
            <span class="n">training_metrics</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
            <span class="n">log_level</span><span class="p">(</span><span class="s1">&#39;Completed epoch </span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">training_metrics</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Defining-The-Training-Routine">
<h3>Defining The Training Routine<a class="headerlink" href="#Defining-The-Training-Routine" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[73]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Pulled from https://codereview.stackexchange.com/questions/169870/decorator-to-measure-execution-time-of-a-function</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">wraps</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="k">import</span> <span class="n">time</span>
<span class="kn">import</span> <span class="nn">datetime</span>

<span class="k">def</span> <span class="nf">timing</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="nd">@wraps</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Elapsed time: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">result</span>
    <span class="k">return</span> <span class="n">wrapper</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[215]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nd">@timing</span>
<span class="k">def</span> <span class="nf">exp_stats</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span>
              <span class="n">all_train_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">all_test_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">n_models</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_models</span><span class="p">,</span>
              <span class="n">lr</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
              <span class="n">n_val</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">training_sets</span><span class="o">=</span><span class="n">train_names</span><span class="p">,</span>
              <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="n">sess</span> <span class="o">=</span> <span class="n">new_session</span><span class="p">()</span>
    <span class="n">stat_metrics</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">()</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer_dict</span><span class="p">[</span><span class="n">optimizer</span><span class="p">]</span>
    <span class="n">exit</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Optimizing using </span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_op</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">train_set</span> <span class="ow">in</span> <span class="n">training_sets</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Using </span><span class="si">{}</span><span class="s1"> training set&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_set</span><span class="p">))</span>
        <span class="n">all_train_metrics</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_train_metrics</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_models</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Starting training for model </span><span class="si">{0}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">all_train_metrics</span><span class="p">)))</span>
                <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">train_stats</span><span class="p">(</span>
                    <span class="n">sess</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                    <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                    <span class="n">init_ops</span><span class="o">=</span><span class="n">init_ops</span><span class="p">,</span>
                    <span class="n">n_val</span><span class="o">=</span><span class="n">n_val</span><span class="p">,</span>
                    <span class="n">train_op</span><span class="o">=</span><span class="n">train_op</span><span class="p">,</span>
                    <span class="n">training_set_name</span><span class="o">=</span><span class="n">train_set</span><span class="p">,</span>
                    <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">all_train_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_metrics</span><span class="p">)</span>

            <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Encountered a KeyboardInterrupt. &#39;</span>
                      <span class="s1">&#39;Starting a IPython Shell.&#39;</span><span class="p">)</span>
                <span class="n">ipy</span><span class="o">.</span><span class="n">embed</span><span class="p">()</span>
                <span class="n">inp</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
                <span class="k">while</span> <span class="n">inp</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">]:</span>
                    <span class="n">inp</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Continue training? [(Y)es/(N)o/(S)kip]&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">inp</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Continuing training...&#39;</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="n">inp</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;s&#39;</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Skipping training set...&#39;</span><span class="p">)</span>
                    <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Exiting&#39;</span><span class="p">)</span>
                    <span class="n">exit</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="n">stat_metrics</span><span class="p">[</span><span class="n">train_set</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_train_metrics</span>

        <span class="k">if</span> <span class="n">exit</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">stat_metrics</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Adam-Optimizer-with-the-Different-Training-Sets">
<h2>Adam Optimizer with the Different Training Sets<a class="headerlink" href="#Adam-Optimizer-with-the-Different-Training-Sets" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Getting-the-Metrics">
<h3>Getting the Metrics<a class="headerlink" href="#Getting-the-Metrics" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">adam_train_metrics</span> <span class="o">=</span> <span class="n">exp_stats</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
    <span class="n">n_models</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_val</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.0033</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[76]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="n">dryrun</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">exp_dir</span> <span class="o">=</span> <span class="n">DIR_DATA_PROC</span> <span class="o">/</span> <span class="s1">&#39;test_statistics&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">exp_dir</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="n">exp_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">()</span>

<span class="n">adam_file_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;adam_train_metrics_5.2.pickle&#39;</span><span class="p">]</span>
<span class="n">adam_file_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">exp_dir</span> <span class="o">/</span> <span class="n">file</span> <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">adam_file_names</span><span class="p">]</span>
<span class="n">adam_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">adam_train_metrics</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">file</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">adam_file_paths</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">dryrun</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">file</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="n">file</span><span class="o">.</span><span class="n">touch</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">file</span><span class="o">.</span><span class="n">exists</span><span class="p">()</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">adam_data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fp</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Wrote to file </span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dryrun: did not write to file </span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Wrote to file /home/abdullah_rashed/work/projects/leabra-tf/data/processed/test_statistics/adam_train_metrics_5.2.pickle
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[729]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">adam_file_paths</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">file</span><span class="o">.</span><span class="n">exists</span><span class="p">(),</span> <span class="n">file</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">),</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
10
[&#39;loss&#39;, &#39;el_acc&#39;, &#39;ax_acc&#39;, &#39;sl_acc&#39;, &#39;sm_acc&#39;, &#39;epoch&#39;]
10
[&#39;1e&#39;, &#39;2e&#39;, &#39;he&#39;, &#39;uni&#39;]
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">sgd_train_metrics</span> <span class="o">=</span> <span class="n">exp_stats</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
    <span class="n">n_models</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_val</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[87]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">len</span><span class="p">(</span><span class="n">sgd_train_metrics</span><span class="p">[</span><span class="s1">&#39;train_1e&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[87]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>10
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[93]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">control_model</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[93]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dict_keys([&#39;loss&#39;, &#39;el_acc&#39;, &#39;ax_acc&#39;, &#39;sl_acc&#39;, &#39;sm_acc&#39;, &#39;epoch&#39;])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[110]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">control_models</span> <span class="o">=</span> <span class="n">adam_train_metrics</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">control_models</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">epoch</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">f</span><span class="s1">&#39;Model </span><span class="si">{i}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_55_0.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_55_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[733]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">dryrun</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">sgd_file_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sgd_train_metrics.pickle&#39;</span><span class="p">,</span> <span class="s1">&#39;sgd_test_metrics.pickle&#39;</span><span class="p">]</span>
<span class="n">sgd_file_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">exp_dir</span> <span class="o">/</span> <span class="n">file</span> <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">sgd_file_names</span><span class="p">]</span>
<span class="n">sgd_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">sgd_train_metrics</span><span class="p">,</span> <span class="n">sgd_test_metrics</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">file</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sgd_file_paths</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">dryrun</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">file</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="n">file</span><span class="o">.</span><span class="n">touch</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">file</span><span class="o">.</span><span class="n">exists</span><span class="p">()</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">sgd_data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fp</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Wrote to file </span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dryrun: did not write to file </span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Wrote to file /home/abdullah_rashed/work/projects/leabra-tf/data/processed/test_statistics/sgd_train_metrics.pickle
Wrote to file /home/abdullah_rashed/work/projects/leabra-tf/data/processed/test_statistics/sgd_test_metrics.pickle
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">met_op_names</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">adam_test_metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;1e&#39;</span><span class="p">][</span><span class="s1">&#39;epoch&#39;</span><span class="p">],</span> <span class="n">adam_test_metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;1e&#39;</span><span class="p">][</span><span class="n">name</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[701]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">met</span> <span class="o">=</span> <span class="s1">&#39;sm_acc&#39;</span>
<span class="k">for</span> <span class="n">test_stat</span> <span class="ow">in</span> <span class="n">test_names</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">adam_test_metrics</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="n">test_stat</span><span class="p">][</span><span class="s1">&#39;epoch&#39;</span><span class="p">],</span>
                 <span class="n">model</span><span class="p">[</span><span class="n">test_stat</span><span class="p">][</span><span class="n">met</span><span class="p">],</span>
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Stat: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_stat</span><span class="p">),</span>
                <span class="p">)</span>

<span class="n">handles</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">get_legend_handles_labels</span><span class="p">()</span>
<span class="n">by_label</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">handles</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">by_label</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">by_label</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="c1"># plt.legend()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_58_0.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_58_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[78]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Losses</span>
<span class="c1"># min_loss_sgd_train = [min(met[&#39;loss&#39;]) for met in sgd_train_metrics]</span>
<span class="c1"># min_loss_adam_train = [min(met[&#39;loss&#39;]) for met in adam_train_metrics]</span>
<span class="n">max_mets_sgd_train</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span> <span class="p">:</span> <span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="n">met</span><span class="p">[</span><span class="s1">&#39;sm_acc&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">met</span> <span class="ow">in</span> <span class="n">sgd_train_metrics</span><span class="p">[</span><span class="n">name</span><span class="p">]]</span>
                      <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">sgd_train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
<span class="n">max_mets_adam_train</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span> <span class="p">:</span> <span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="n">met</span><span class="p">[</span><span class="s1">&#39;sm_acc&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">met</span> <span class="ow">in</span> <span class="n">adam_train_metrics</span><span class="p">[</span><span class="n">name</span><span class="p">]]</span>
                       <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">adam_train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[79]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">optimizer_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="s1">&#39;SGD&#39;</span><span class="p">],</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">optimizer_labels</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[79]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([&#39;Adam&#39;, &#39;Adam&#39;, &#39;Adam&#39;, &#39;Adam&#39;, &#39;Adam&#39;, &#39;Adam&#39;, &#39;Adam&#39;, &#39;Adam&#39;,
       &#39;Adam&#39;, &#39;Adam&#39;, &#39;SGD&#39;, &#39;SGD&#39;, &#39;SGD&#39;, &#39;SGD&#39;, &#39;SGD&#39;, &#39;SGD&#39;, &#39;SGD&#39;,
       &#39;SGD&#39;, &#39;SGD&#39;, &#39;SGD&#39;], dtype=&#39;&lt;U4&#39;)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[80]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">adam_train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[80]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dict_keys([&#39;train_1e&#39;, &#39;train_2e&#39;, &#39;train_he&#39;, &#39;train_uni&#39;])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[81]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">adam_train_metrics</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[81]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dict_keys([&#39;loss&#39;, &#39;el_acc&#39;, &#39;ax_acc&#39;, &#39;sl_acc&#39;, &#39;sm_acc&#39;, &#39;epoch&#39;])
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[83]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># data_loss = min_loss_adam_train + min_loss_sgd_train</span>
<span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span> <span class="p">:</span> <span class="n">max_mets_adam_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+</span> <span class="n">max_mets_sgd_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">max_mets_adam_train</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
<span class="c1"># data_dict[&#39;Loss&#39;] = data_loss</span>
<span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;Optimizer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer_labels</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[84]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">metric_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">metric_values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">optimizer_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">max_mets_adam_train</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">metric_values</span> <span class="o">+=</span> <span class="n">max_mets_adam_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+</span> <span class="n">max_mets_sgd_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    <span class="n">metric_labels</span> <span class="o">+=</span>  <span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">*</span> <span class="mi">20</span>
    <span class="n">optimizer_labels</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;Adam&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;SGD&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>

</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[85]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Values&#39;</span> <span class="p">:</span> <span class="n">metric_values</span><span class="p">,</span>
             <span class="s1">&#39;Datasets&#39;</span> <span class="p">:</span> <span class="n">metric_labels</span><span class="p">,</span>
             <span class="s1">&#39;Optimizer&#39;</span> <span class="p">:</span> <span class="n">optimizer_labels</span><span class="p">}</span>
<span class="n">data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_dict</span><span class="p">)</span>
<span class="n">data_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[85]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Values</th>
      <th>Datasets</th>
      <th>Optimizer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
</div>
<div class="section" id="Plotting-Results">
<h2>Plotting Results<a class="headerlink" href="#Plotting-Results" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Comparing-Datasets">
<h3>Comparing Datasets<a class="headerlink" href="#Comparing-Datasets" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[86]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">sns</span><span class="o">.</span><span class="n">swarmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Datasets&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Values&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Optimizer&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sample Accuracy of Adam vs SGD&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_68_0.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_68_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="Debugging-the-Increasing-Validation-Loss">
<h2>Debugging the Increasing Validation Loss<a class="headerlink" href="#Debugging-the-Increasing-Validation-Loss" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[139]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">control_metrics</span> <span class="o">=</span> <span class="n">exp_stats</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">n_models</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_val</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.0033</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span>
    <span class="n">training_sets</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2019-05-28 14:14:29 x7 leabratf[24947] INFO Optimizing using Adam_1
2019-05-28 14:14:29 x7 leabratf[24947] INFO Using train_uni training set
2019-05-28 14:14:29 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 14:14:29 x7 leabratf[24947] INFO Beginning training using learning rate, 0.0033, Adam_1 training routine, for 500 epochs, on train_uni training set.
2019-05-28 14:14:31 x7 leabratf[24947] INFO Completed epoch 0
2019-05-28 14:14:35 x7 leabratf[24947] INFO Completed epoch 10
2019-05-28 14:14:39 x7 leabratf[24947] INFO Completed epoch 20
2019-05-28 14:14:43 x7 leabratf[24947] INFO Completed epoch 30
2019-05-28 14:14:47 x7 leabratf[24947] INFO Completed epoch 40
2019-05-28 14:14:51 x7 leabratf[24947] INFO Completed epoch 50
2019-05-28 14:14:55 x7 leabratf[24947] INFO Completed epoch 60
2019-05-28 14:14:58 x7 leabratf[24947] INFO Completed epoch 70
2019-05-28 14:15:02 x7 leabratf[24947] INFO Completed epoch 80
2019-05-28 14:15:06 x7 leabratf[24947] INFO Completed epoch 90
2019-05-28 14:15:10 x7 leabratf[24947] INFO Completed epoch 100
2019-05-28 14:15:14 x7 leabratf[24947] INFO Completed epoch 110
2019-05-28 14:15:18 x7 leabratf[24947] INFO Completed epoch 120
2019-05-28 14:15:22 x7 leabratf[24947] INFO Completed epoch 130
2019-05-28 14:15:26 x7 leabratf[24947] INFO Completed epoch 140
2019-05-28 14:15:30 x7 leabratf[24947] INFO Completed epoch 150
2019-05-28 14:15:33 x7 leabratf[24947] INFO Completed epoch 160
2019-05-28 14:15:37 x7 leabratf[24947] INFO Completed epoch 170
2019-05-28 14:15:41 x7 leabratf[24947] INFO Completed epoch 180
2019-05-28 14:15:45 x7 leabratf[24947] INFO Completed epoch 190
2019-05-28 14:15:49 x7 leabratf[24947] INFO Completed epoch 200
2019-05-28 14:15:53 x7 leabratf[24947] INFO Completed epoch 210
2019-05-28 14:15:56 x7 leabratf[24947] INFO Completed epoch 220
2019-05-28 14:16:00 x7 leabratf[24947] INFO Completed epoch 230
2019-05-28 14:16:04 x7 leabratf[24947] INFO Completed epoch 240
2019-05-28 14:16:08 x7 leabratf[24947] INFO Completed epoch 250
2019-05-28 14:16:12 x7 leabratf[24947] INFO Completed epoch 260
2019-05-28 14:16:16 x7 leabratf[24947] INFO Completed epoch 270
2019-05-28 14:16:20 x7 leabratf[24947] INFO Completed epoch 280
2019-05-28 14:16:23 x7 leabratf[24947] INFO Completed epoch 290
2019-05-28 14:16:27 x7 leabratf[24947] INFO Completed epoch 300
2019-05-28 14:16:31 x7 leabratf[24947] INFO Completed epoch 310
2019-05-28 14:16:35 x7 leabratf[24947] INFO Completed epoch 320
2019-05-28 14:16:39 x7 leabratf[24947] INFO Completed epoch 330
2019-05-28 14:16:43 x7 leabratf[24947] INFO Completed epoch 340
2019-05-28 14:16:47 x7 leabratf[24947] INFO Completed epoch 350
2019-05-28 14:16:50 x7 leabratf[24947] INFO Completed epoch 360
2019-05-28 14:16:54 x7 leabratf[24947] INFO Completed epoch 370
2019-05-28 14:16:58 x7 leabratf[24947] INFO Completed epoch 380
2019-05-28 14:17:02 x7 leabratf[24947] INFO Completed epoch 390
2019-05-28 14:17:06 x7 leabratf[24947] INFO Completed epoch 400
2019-05-28 14:17:10 x7 leabratf[24947] INFO Completed epoch 410
2019-05-28 14:17:13 x7 leabratf[24947] INFO Completed epoch 420
2019-05-28 14:17:17 x7 leabratf[24947] INFO Completed epoch 430
2019-05-28 14:17:21 x7 leabratf[24947] INFO Completed epoch 440
2019-05-28 14:17:25 x7 leabratf[24947] INFO Completed epoch 450
2019-05-28 14:17:29 x7 leabratf[24947] INFO Completed epoch 460
2019-05-28 14:17:33 x7 leabratf[24947] INFO Completed epoch 470
2019-05-28 14:17:37 x7 leabratf[24947] INFO Completed epoch 480
2019-05-28 14:17:40 x7 leabratf[24947] INFO Completed epoch 490
2019-05-28 14:17:44 x7 leabratf[24947] INFO Completed epoch 499
2019-05-28 14:17:44 x7 leabratf[24947] INFO Elapsed time: 0:03:14.617946
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">control_metrics</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[141]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">control_metrics</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">control_metrics</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;epoch&#39;</span><span class="p">],</span>
         <span class="n">control_metrics</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Val Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_72_0.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_72_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[197]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">training_set_name</span> <span class="o">=</span> <span class="s1">&#39;train_uni&#39;</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_ops</span><span class="p">)</span>
    <span class="c1"># Define training and validation handlers</span>
    <span class="n">handles</span> <span class="o">=</span> <span class="n">pdict</span><span class="p">({</span><span class="n">name</span> <span class="p">:</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">iterators</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">string_handle</span><span class="p">())</span>
                    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">iterators</span><span class="o">.</span><span class="n">keys</span><span class="p">()})</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
        <span class="n">alpha_ph</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">handler</span><span class="p">:</span> <span class="n">handles</span><span class="p">[</span><span class="n">training_set_name</span><span class="p">]})</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
        <span class="n">alpha_ph</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">handler</span><span class="p">:</span> <span class="n">handles</span><span class="o">.</span><span class="n">test</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(1, 4, 5, 5)
(500, 4, 5, 5)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[167]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cgh</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">cgh</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">y_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">x_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">x_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_74_0.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_74_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_74_1.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_74_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[201]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">control_metrics</span> <span class="o">=</span> <span class="n">exp_stats</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">n_models</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_val</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.0033</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span>
    <span class="n">training_sets</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2019-05-28 15:33:48 x7 leabratf[24947] INFO Optimizing using Adam
2019-05-28 15:33:48 x7 leabratf[24947] INFO Using train_uni training set
2019-05-28 15:33:48 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 15:33:48 x7 leabratf[24947] INFO Beginning training using learning rate, 0.0033, Adam training routine, for 100 epochs, on train_uni training set. Testing using test dataset.
2019-05-28 15:33:49 x7 leabratf[24947] INFO Completed epoch 0
2019-05-28 15:33:51 x7 leabratf[24947] INFO Completed epoch 10
2019-05-28 15:33:53 x7 leabratf[24947] INFO Completed epoch 20
2019-05-28 15:33:55 x7 leabratf[24947] INFO Completed epoch 30
2019-05-28 15:33:57 x7 leabratf[24947] INFO Completed epoch 40
2019-05-28 15:33:59 x7 leabratf[24947] INFO Completed epoch 50
2019-05-28 15:34:01 x7 leabratf[24947] INFO Completed epoch 60
2019-05-28 15:34:03 x7 leabratf[24947] INFO Completed epoch 70
2019-05-28 15:34:05 x7 leabratf[24947] INFO Completed epoch 80
2019-05-28 15:34:07 x7 leabratf[24947] INFO Completed epoch 90
2019-05-28 15:34:09 x7 leabratf[24947] INFO Completed epoch 99
2019-05-28 15:34:09 x7 leabratf[24947] INFO Elapsed time: 0:00:20.926532
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[202]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">control_metrics</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">control_metrics</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;epoch&#39;</span><span class="p">],</span>
         <span class="n">control_metrics</span><span class="p">[</span><span class="s1">&#39;train_uni&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Val Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_76_0.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_76_0.png" />
</div>
</div>
<p>The batch sizes were totally wrong between the training and test sets. Fixing them in the exp configs all the way at the top of the notebook solved the problem.</p>
</div>
<div class="section" id="Rerunning-the-Analysis">
<h2>Rerunning the Analysis<a class="headerlink" href="#Rerunning-the-Analysis" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[220]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">adam_train_metrics</span> <span class="o">=</span> <span class="n">exp_stats</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">n_models</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_val</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.0033</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2019-05-28 15:43:08 x7 leabratf[24947] INFO Optimizing using Adam
2019-05-28 15:43:08 x7 leabratf[24947] INFO Using train_1e training set
2019-05-28 15:43:08 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 15:45:55 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 15:48:42 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 15:51:29 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 15:54:16 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 15:57:03 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 15:59:49 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 16:02:35 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 16:05:22 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 16:08:08 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 16:10:55 x7 leabratf[24947] INFO Using train_2e training set
2019-05-28 16:10:55 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 16:13:42 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 16:16:29 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 16:19:16 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 16:22:03 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 16:24:51 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 16:27:38 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 16:30:25 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 16:33:12 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 16:36:00 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 16:38:47 x7 leabratf[24947] INFO Using train_he training set
2019-05-28 16:38:47 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 16:41:34 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 16:44:21 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 16:47:08 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 16:49:55 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 16:52:43 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 16:55:30 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 16:58:17 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 17:01:04 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 17:03:51 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 17:06:38 x7 leabratf[24947] INFO Using train_uni training set
2019-05-28 17:06:38 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 17:09:25 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 17:12:13 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 17:15:00 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 17:17:47 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 17:20:34 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 17:23:21 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 17:26:08 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 17:28:55 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 17:31:43 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 17:34:30 x7 leabratf[24947] INFO Elapsed time: 1:51:22.297224
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 4h 46min 35s, sys: 52min 20s, total: 5h 38min 55s
Wall time: 1h 51min 22s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[221]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">sgd_train_metrics</span> <span class="o">=</span> <span class="n">exp_stats</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">n_models</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_val</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2019-05-28 17:34:30 x7 leabratf[24947] INFO Optimizing using GradientDescent
2019-05-28 17:34:30 x7 leabratf[24947] INFO Using train_1e training set
2019-05-28 17:34:30 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 17:36:51 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 17:39:12 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 17:41:32 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 17:43:53 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 17:46:14 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 17:48:35 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 17:50:57 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 17:53:18 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 17:55:39 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 17:57:57 x7 leabratf[24947] INFO Using train_2e training set
2019-05-28 17:57:57 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 18:00:10 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 18:02:22 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 18:04:41 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 18:07:02 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 18:09:24 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 18:11:45 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 18:14:07 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 18:16:28 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 18:18:50 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 18:21:12 x7 leabratf[24947] INFO Using train_he training set
2019-05-28 18:21:12 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 18:23:33 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 18:25:54 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 18:28:15 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 18:30:37 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 18:32:59 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 18:35:20 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 18:37:42 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 18:40:04 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 18:42:26 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 18:44:48 x7 leabratf[24947] INFO Using train_uni training set
2019-05-28 18:44:48 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 18:47:10 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 18:49:31 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 18:51:53 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 18:54:15 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 18:56:37 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 18:58:59 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 19:01:21 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 19:03:43 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 19:06:05 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 19:08:27 x7 leabratf[24947] INFO Elapsed time: 1:33:56.581223
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 3h 52min 48s, sys: 41min 46s, total: 4h 34min 35s
Wall time: 1h 33min 56s
</pre></div></div>
</div>
<div class="section" id="New-Plots">
<h3>New Plots<a class="headerlink" href="#New-Plots" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[222]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Losses</span>
<span class="c1"># min_loss_sgd_train = [min(met[&#39;loss&#39;]) for met in sgd_train_metrics]</span>
<span class="c1"># min_loss_adam_train = [min(met[&#39;loss&#39;]) for met in adam_train_metrics]</span>
<span class="n">max_mets_sgd_train</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span> <span class="p">:</span> <span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="n">met</span><span class="p">[</span><span class="s1">&#39;sm_acc&#39;</span><span class="p">])</span>
                              <span class="k">for</span> <span class="n">met</span> <span class="ow">in</span> <span class="n">sgd_train_metrics</span><span class="p">[</span><span class="n">name</span><span class="p">]]</span>
                      <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">sgd_train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
<span class="n">max_mets_adam_train</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span> <span class="p">:</span> <span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="n">met</span><span class="p">[</span><span class="s1">&#39;sm_acc&#39;</span><span class="p">])</span>
                               <span class="k">for</span> <span class="n">met</span> <span class="ow">in</span> <span class="n">adam_train_metrics</span><span class="p">[</span><span class="n">name</span><span class="p">]]</span>
                       <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">adam_train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
<span class="n">optimizer_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="s1">&#39;SGD&#39;</span><span class="p">],</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1"># data_loss = min_loss_adam_train + min_loss_sgd_train</span>
<span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span> <span class="p">:</span> <span class="n">max_mets_adam_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+</span> <span class="n">max_mets_sgd_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">max_mets_adam_train</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
<span class="c1"># data_dict[&#39;Loss&#39;] = data_loss</span>
<span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;Optimizer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer_labels</span>

<span class="n">metric_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">metric_values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">optimizer_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">max_mets_adam_train</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">metric_values</span> <span class="o">+=</span> <span class="n">max_mets_adam_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+</span> <span class="n">max_mets_sgd_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    <span class="n">metric_labels</span> <span class="o">+=</span>  <span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">*</span> <span class="mi">20</span>
    <span class="n">optimizer_labels</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;Adam&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;SGD&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>

<span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Values&#39;</span> <span class="p">:</span> <span class="n">metric_values</span><span class="p">,</span>
             <span class="s1">&#39;Datasets&#39;</span> <span class="p">:</span> <span class="n">metric_labels</span><span class="p">,</span>
             <span class="s1">&#39;Optimizer&#39;</span> <span class="p">:</span> <span class="n">optimizer_labels</span><span class="p">}</span>
<span class="n">data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_dict</span><span class="p">)</span>
<span class="n">data_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[222]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Values</th>
      <th>Datasets</th>
      <th>Optimizer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.214</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.254</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.238</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.256</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.252</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[223]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">sns</span><span class="o">.</span><span class="n">swarmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Datasets&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Values&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Optimizer&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sample Accuracy of Adam vs SGD&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_83_0.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_83_0.png" />
</div>
</div>
</div>
<div class="section" id="Extra-Epochs-for-SGD">
<h3>Extra Epochs for SGD<a class="headerlink" href="#Extra-Epochs-for-SGD" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[224]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">sgd_train_metrics_ext</span> <span class="o">=</span> <span class="n">exp_stats</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">2500</span><span class="p">,</span>
    <span class="n">n_models</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_val</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2019-05-28 21:59:41 x7 leabratf[24947] INFO Optimizing using GradientDescent
2019-05-28 21:59:41 x7 leabratf[24947] INFO Using train_1e training set
2019-05-28 21:59:41 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 22:05:35 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 22:11:29 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 22:17:22 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 22:23:16 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 22:29:09 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 22:34:43 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 22:40:13 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 22:45:43 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 22:51:13 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 22:56:44 x7 leabratf[24947] INFO Using train_2e training set
2019-05-28 22:56:44 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 23:02:14 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-28 23:07:44 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-28 23:13:13 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-28 23:18:42 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-28 23:24:12 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-28 23:29:42 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-28 23:35:12 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-28 23:40:41 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-28 23:46:10 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-28 23:51:40 x7 leabratf[24947] INFO Using train_he training set
2019-05-28 23:51:40 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-28 23:57:08 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-29 00:02:38 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-29 00:08:08 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-29 00:13:37 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-29 00:19:06 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-29 00:24:36 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-29 00:30:06 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-29 00:35:35 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-29 00:41:05 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-29 00:46:35 x7 leabratf[24947] INFO Using train_uni training set
2019-05-29 00:46:35 x7 leabratf[24947] INFO Starting training for model 0.
2019-05-29 00:52:05 x7 leabratf[24947] INFO Starting training for model 1.
2019-05-29 00:57:35 x7 leabratf[24947] INFO Starting training for model 2.
2019-05-29 01:03:05 x7 leabratf[24947] INFO Starting training for model 3.
2019-05-29 01:08:36 x7 leabratf[24947] INFO Starting training for model 4.
2019-05-29 01:14:06 x7 leabratf[24947] INFO Starting training for model 5.
2019-05-29 01:19:37 x7 leabratf[24947] INFO Starting training for model 6.
2019-05-29 01:25:06 x7 leabratf[24947] INFO Starting training for model 7.
2019-05-29 01:30:37 x7 leabratf[24947] INFO Starting training for model 8.
2019-05-29 01:36:07 x7 leabratf[24947] INFO Starting training for model 9.
2019-05-29 01:41:38 x7 leabratf[24947] INFO Elapsed time: 3:41:56.411266
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 9h 15min 48s, sys: 1h 37min 22s, total: 10h 53min 10s
Wall time: 3h 41min 56s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[225]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Losses</span>
<span class="c1"># min_loss_sgd_train = [min(met[&#39;loss&#39;]) for met in sgd_train_metrics]</span>
<span class="c1"># min_loss_adam_train = [min(met[&#39;loss&#39;]) for met in adam_train_metrics]</span>
<span class="n">max_mets_sgd_train</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span> <span class="p">:</span> <span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="n">met</span><span class="p">[</span><span class="s1">&#39;sm_acc&#39;</span><span class="p">])</span>
                              <span class="k">for</span> <span class="n">met</span> <span class="ow">in</span> <span class="n">sgd_train_metrics_ext</span><span class="p">[</span><span class="n">name</span><span class="p">]]</span>
                      <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">sgd_train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
<span class="n">max_mets_adam_train</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span> <span class="p">:</span> <span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="n">met</span><span class="p">[</span><span class="s1">&#39;sm_acc&#39;</span><span class="p">])</span>
                               <span class="k">for</span> <span class="n">met</span> <span class="ow">in</span> <span class="n">adam_train_metrics</span><span class="p">[</span><span class="n">name</span><span class="p">]]</span>
                       <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">adam_train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
<span class="n">optimizer_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="s1">&#39;SGD&#39;</span><span class="p">],</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1"># data_loss = min_loss_adam_train + min_loss_sgd_train</span>
<span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span> <span class="p">:</span> <span class="n">max_mets_adam_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+</span> <span class="n">max_mets_sgd_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">max_mets_adam_train</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
<span class="c1"># data_dict[&#39;Loss&#39;] = data_loss</span>
<span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;Optimizer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer_labels</span>

<span class="n">metric_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">metric_values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">optimizer_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">max_mets_adam_train</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">metric_values</span> <span class="o">+=</span> <span class="n">max_mets_adam_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+</span> <span class="n">max_mets_sgd_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    <span class="n">metric_labels</span> <span class="o">+=</span>  <span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">*</span> <span class="mi">20</span>
    <span class="n">optimizer_labels</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;Adam&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;SGD&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>

<span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Values&#39;</span> <span class="p">:</span> <span class="n">metric_values</span><span class="p">,</span>
             <span class="s1">&#39;Datasets&#39;</span> <span class="p">:</span> <span class="n">metric_labels</span><span class="p">,</span>
             <span class="s1">&#39;Optimizer&#39;</span> <span class="p">:</span> <span class="n">optimizer_labels</span><span class="p">}</span>
<span class="n">data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_dict</span><span class="p">)</span>
<span class="n">data_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[225]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Values</th>
      <th>Datasets</th>
      <th>Optimizer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.214</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.254</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.238</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.256</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.252</td>
      <td>train_1e</td>
      <td>Adam</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="section" id="New-Plot-with-2500-Epochs-for-SGD">
<h4>New Plot with 2500 Epochs for SGD<a class="headerlink" href="#New-Plot-with-2500-Epochs-for-SGD" title="Permalink to this headline">¶</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[229]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">sns</span><span class="o">.</span><span class="n">swarmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Datasets&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Values&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Optimizer&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sample Accuracy of Adam vs SGD on Uniform Datasets&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Training Datasets&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_88_0.png" src="../_images/notebooks_0.5.2-Adam-With-Non-Uniform-Training-Statistics_88_0.png" />
</div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="0.6-Hebbian-Learning.html" class="btn btn-neutral float-right" title="0.6 Hebbian Learning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="0.5.1-Adam-With-Non-Uniform-Task-Statistics.html" class="btn btn-neutral float-left" title="0.5.1 Adam with Non-Uniform Task Statistics" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>