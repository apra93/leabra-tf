

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>0.3 BP Model in Tensorflow &mdash; Leabra Tensorflow 0+untagged.81.g9106ca2 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="0.3.1 Comparing Accuracy Metrics" href="0.3.1-Comparing-Accuracy-Metrics.html" />
    <link rel="prev" title="0.2.1 Iterating the BP Model on GPUs" href="0.2.1-Iterating-the-BP-Model-on-GPUs.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Leabra Tensorflow
          

          
          </a>

          
            
            
              <div class="version">
                0+untagged.81.g9106ca2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../release_schedule.html">Release Schedule</a></li>
</ul>
<p class="caption"><span class="caption-text">Tasks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../combinatorics.html">Combinatorial Generalizaton and Interactivity</a></li>
</ul>
<p class="caption"><span class="caption-text">Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../visualization.html">Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">Utility Functions</a></li>
</ul>
<p class="caption"><span class="caption-text">Notebooks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="0.0-Notebook-Template.html">0.0 Leabra-tf Notebook Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1-Designing-the-Combigen-Task.html">0.1 Implementing the Combinatorial Generalization Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.1-Combigen-All-True-Bug-Fix.html">0.1.1 Combigen All-True Bug Fix</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.2-Combigen-Stacks.html">0.1.2 Combigen Stacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.3-Specifying-the-Number-of-Lines.html">0.1.3 Specifying the Number of Lines</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.2-Running-a-Basic-Model-on-Combigen.html">0.2 Running a Basic Model on Combigen</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.2.1-Iterating-the-BP-Model-on-GPUs.html">0.2.1 Iterating the BP Model on GPUs</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">0.3 BP Model in Tensorflow</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Boilerplate">Boilerplate</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Jupyter-Extensions">Jupyter Extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Imports">Imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Initial-Setup">Initial Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Global-Variables">Global Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Combigen-Task-Variables">Combigen Task Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Data-Parameters">Data Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Datasets">Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Network-Parameters">Network Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Training-Parameters">Training Parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Background">Background</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#The-Combigen-Task">The Combigen Task</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Keras-Implementation">Keras Implementation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#The-Tensorflow-Pipeline">The Tensorflow Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Variables">Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Datasets">Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#O'Reilly-Model">O’Reilly Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-Loss-Function">The Loss Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Metrics">Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#New-Session-Function">New Session Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Training-the-Model">Training the Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Recreating-the-BCE+E-Training-Curves">Recreating the BCE+E Training Curves</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#The-Legend">The Legend</a></li>
<li class="toctree-l3"><a class="reference internal" href="#500-Epochs">500 Epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#10-x-500-Epochs">10 x 500 Epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#50-x-500-Epochs">50 x 500 Epochs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="0.3.1-Comparing-Accuracy-Metrics.html">0.3.1 Comparing Accuracy Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.4-Exploring-Different-Learning-Rates.html">0.4 Exploring Different Learning Rates</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.4.1-Exploring-Different-Optimizers.html">0.4 Exploring Different Optimizers</a></li>
</ul>
<p class="caption"><span class="caption-text">Project Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://apra93.github.io/leabra-tf/">Home</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apra93/leabra-tf/">Github</a></li>
<li class="toctree-l1"><a class="reference external" href="https://travis-ci.org/apra93/leabra-tf">Travis CI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://codecov.io/gh/apra93/leabra-tf">Codecov</a></li>
<li class="toctree-l1"><a class="reference external" href="https://app.codacy.com/project/apra93/leabra-tf/dashboard">Codacy</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Leabra Tensorflow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>0.3 BP Model in Tensorflow</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/0.3-BP-Model-in-Tensorflow.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="0.3-BP-Model-in-Tensorflow">
<h1>0.3 BP Model in Tensorflow<a class="headerlink" href="#0.3-BP-Model-in-Tensorflow" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Boilerplate">
<h2>Boilerplate<a class="headerlink" href="#Boilerplate" title="Permalink to this headline">¶</a></h2>
<p>The following subsections are largely boilerplate code, so skip around as needed.</p>
<div class="section" id="Jupyter-Extensions">
<h3>Jupyter Extensions<a class="headerlink" href="#Jupyter-Extensions" title="Permalink to this headline">¶</a></h3>
<p>Load <a class="reference external" href="https://github.com/rasbt/watermark">watermark</a> to see the state of the machine and environment that’s running the notebook. To make sense of the options, take a look at the <a class="reference external" href="https://github.com/rasbt/watermark#usage">usage</a> section of the readme.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Load `watermark` extension</span>
<span class="o">%</span><span class="k">load_ext</span> watermark
<span class="c1"># Display the status of the machine and packages. Add more as necessary.</span>
<span class="o">%</span><span class="k">watermark</span> -v -n -m -g -b -t -p numpy,matplotlib,seaborn,tensorflow
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sun Mar 03 2019 01:37:24

CPython 3.6.8
IPython 7.3.0

numpy 1.16.2
matplotlib 3.0.3
seaborn 0.9.0
tensorflow 1.12.0

compiler   : GCC 7.3.0
system     : Linux
release    : 4.4.0-130-generic
machine    : x86_64
processor  : x86_64
CPU cores  : 12
interpreter: 64bit
Git hash   : edd22d45c1c38e765037bf04d03c4caf4494dc66
Git branch : master
</pre></div></div>
</div>
<p>Load <a class="reference external" href="https://ipython.org/ipython-doc/3/config/extensions/autoreload.html">autoreload</a> which will always reload modules marked with <code class="docutils literal notranslate"><span class="pre">%aimport</span></code>.</p>
<p>This behavior can be inverted by running <code class="docutils literal notranslate"><span class="pre">autoreload</span> <span class="pre">2</span></code> which will set everything to be auto-reloaded <em>except</em> for modules marked with <code class="docutils literal notranslate"><span class="pre">%aimport</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Load `autoreload` extension</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="c1"># Set autoreload behavior</span>
<span class="o">%</span><span class="k">autoreload</span> 1
</pre></div>
</div>
</div>
<p>Load <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> in one of the more <code class="docutils literal notranslate"><span class="pre">jupyter</span></code>-friendly <a class="reference external" href="https://ipython.readthedocs.io/en/stable/interactive/plotting.html">rich-output modes</a>. Some options (that may or may not have worked) are <code class="docutils literal notranslate"><span class="pre">inline</span></code>, <code class="docutils literal notranslate"><span class="pre">notebook</span></code>, and <code class="docutils literal notranslate"><span class="pre">gtk</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Set the matplotlib mode</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="section" id="Imports">
<h3>Imports<a class="headerlink" href="#Imports" title="Permalink to this headline">¶</a></h3>
<p>Static imports that shouldn’t necessarily change throughout the notebook.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[410]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Standard library imports</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">reduce</span>

<span class="c1"># Third party</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
</div>
<p>Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Task script</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.tasks.combinatorics.combigen
<span class="kn">import</span> <span class="nn">leabratf.tasks.combinatorics.combigen</span> <span class="k">as</span> <span class="nn">cg</span>
<span class="c1"># Visualization for the task</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.visualization.combigen_heatmap
<span class="kn">import</span> <span class="nn">leabratf.visualization.combigen_heatmap</span> <span class="k">as</span> <span class="nn">cgh</span>
<span class="c1"># Utility functions</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.utils
<span class="kn">from</span> <span class="nn">leabratf.utils</span> <span class="k">import</span> <span class="n">setup_logging</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.constants
<span class="kn">from</span> <span class="nn">leabratf.constants</span> <span class="k">import</span> <span class="n">DIR_MODELS</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Initial-Setup">
<h3>Initial Setup<a class="headerlink" href="#Initial-Setup" title="Permalink to this headline">¶</a></h3>
<p>Set <a class="reference external" href="https://seaborn.pydata.org/generated/seaborn.set.html">seaborn defaults</a> for matplotlib.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Set up the logger configuration to something more useful than baseline. Creates log files for the different log levels in the <code class="docutils literal notranslate"><span class="pre">logs</span></code> directory.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">logging.yml</span></code> for the exact logging configuration.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Run base logger setup</span>
<span class="c1"># setup_logging()</span>
<span class="c1"># Define a logger object</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;leabratf&#39;</span><span class="p">)</span>
<span class="c1"># Don&#39;t propagate messages</span>
<span class="n">logger</span><span class="o">.</span><span class="n">propagate</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Global-Variables">
<h3>Global Variables<a class="headerlink" href="#Global-Variables" title="Permalink to this headline">¶</a></h3>
<div class="section" id="Combigen-Task-Variables">
<h4>Combigen Task Variables<a class="headerlink" href="#Combigen-Task-Variables" title="Permalink to this headline">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Number of slots in a training set</span>
<span class="n">STACK</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1"># Size of each axis in the input array</span>
<span class="n">SIZE</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># Number of axes to use per slot</span>
<span class="n">DIMS</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Data-Parameters">
<h4>Data Parameters<a class="headerlink" href="#Data-Parameters" title="Permalink to this headline">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Number of epochs to train for</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">500</span>
<span class="c1"># Number of samples in the training set</span>
<span class="n">N_TRAIN</span><span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Number of samples in the validation set</span>
<span class="n">N_VAL</span> <span class="o">=</span> <span class="mi">50</span>
<span class="c1"># Number of samples in the testing set</span>
<span class="n">N_TEST</span> <span class="o">=</span> <span class="mi">500</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Datasets">
<h4>Datasets<a class="headerlink" href="#Datasets" title="Permalink to this headline">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Training Data</span>
<span class="n">Y_TRAIN</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">generate_labels</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N_TRAIN</span><span class="p">,</span> <span class="n">stack</span><span class="o">=</span><span class="n">STACK</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">DIMS</span><span class="p">)</span>
<span class="n">X_TRAIN</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">Y_TRAIN</span><span class="p">)</span>
<span class="c1"># Validation Data</span>
<span class="n">Y_VAL</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">generate_labels</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N_VAL</span><span class="p">,</span> <span class="n">stack</span><span class="o">=</span><span class="n">STACK</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">DIMS</span><span class="p">)</span>
<span class="n">X_VAL</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">Y_VAL</span><span class="p">)</span>
<span class="c1"># Testing data</span>
<span class="n">Y_TEST</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">generate_labels</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N_TEST</span><span class="p">,</span> <span class="n">stack</span><span class="o">=</span><span class="n">STACK</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">DIMS</span><span class="p">)</span>
<span class="n">X_TEST</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">Y_TEST</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Network-Parameters">
<h4>Network Parameters<a class="headerlink" href="#Network-Parameters" title="Permalink to this headline">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[79]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Learning rate</span>
<span class="n">ALPHA</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="c1"># Batch size</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Number of parameters in the inputs</span>
<span class="n">N_INPUTS</span> <span class="o">=</span> <span class="n">STACK</span> <span class="o">*</span> <span class="n">SIZE</span> <span class="o">**</span> <span class="n">DIMS</span>
<span class="c1"># Number of hidden units</span>
<span class="n">N_HIDDEN_1</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Number of parameters in the labels</span>
<span class="n">N_OUTPUTS</span> <span class="o">=</span> <span class="n">STACK</span> <span class="o">*</span> <span class="n">SIZE</span> <span class="o">*</span> <span class="n">DIMS</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training-Parameters">
<h4>Training Parameters<a class="headerlink" href="#Training-Parameters" title="Permalink to this headline">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[479]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Number of times to print an update</span>
<span class="n">N_UPDATES</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># Which device to train on</span>
<span class="n">TF_DEVICE</span> <span class="o">=</span> <span class="s1">&#39;/cpu:0&#39;</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="Background">
<h2>Background<a class="headerlink" href="#Background" title="Permalink to this headline">¶</a></h2>
<p>This section goes over some of the background information for the notebook using results from previous notebooks. Skip around as needed.</p>
<div class="section" id="The-Combigen-Task">
<h3>The Combigen Task<a class="headerlink" href="#The-Combigen-Task" title="Permalink to this headline">¶</a></h3>
<p>Quickly remind ourselves what the task looks like before diving in.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cgh</span><span class="o">.</span><span class="n">visualize_combigen</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.3-BP-Model-in-Tensorflow_32_0.png" src="../_images/notebooks_0.3-BP-Model-in-Tensorflow_32_0.png" />
</div>
</div>
</div>
<div class="section" id="Keras-Implementation">
<h3>Keras Implementation<a class="headerlink" href="#Keras-Implementation" title="Permalink to this headline">¶</a></h3>
<p>In nb-0.2.x, the O’Reilly BP model was implemented in keras with the code having this general structure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bp_model_bce</span><span class="p">(</span><span class="n">hidden_units</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stack</span><span class="o">=</span><span class="n">STACK</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">DIMS</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Builds and returns the model&quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="n">stack</span><span class="o">*</span><span class="n">size</span><span class="o">*</span><span class="n">size</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Initial_reshape&#39;</span><span class="p">))</span>
    <span class="c1"># Single hidden layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Hidden_Layer&#39;</span><span class="p">))</span>
    <span class="c1"># Output layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">stack</span><span class="o">*</span><span class="n">size</span><span class="o">*</span><span class="n">dims</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Output_Layer&#39;</span><span class="p">))</span>
    <span class="c1"># Reshape to match the labels</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="n">stack</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dims</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Output_reshape&#39;</span><span class="p">))</span>

    <span class="c1"># Loss and optimizer to use, along with metrics to track</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
                  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>With the main difference between models tested in nb-0.2.1 being the loss functions. The two most interesting models had the following training curves:</p>
<p><a href="#id3"><span class="problematic" id="id4">|BCE\_SGD|</span></a></p>
<p><a href="#id5"><span class="problematic" id="id6">|MSE\_SGD|</span></a></p>
<p>Some things to note are that the models were trained to 10 times the number of epochs as O’Reilly did (500). However, a dotted vertical line was added at the 500 epoch mark to make it clear what the model’s performance would have looked like.</p>
</div>
</div>
<div class="section" id="The-Tensorflow-Pipeline">
<h2>The Tensorflow Pipeline<a class="headerlink" href="#The-Tensorflow-Pipeline" title="Permalink to this headline">¶</a></h2>
<p>Using the results of the keras implementation as the benchmark for this model, let’s rewrite the model using pure tensorflow. Let’s start by resetting the graph and then defining the weights and associated biases.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[480]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Cleanup any residual nodes</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="Variables">
<h3>Variables<a class="headerlink" href="#Variables" title="Permalink to this headline">¶</a></h3>
<p>Straight forward section where we define the weights and biases. One thing to note is that the weights are initialized using the <code class="docutils literal notranslate"><span class="pre">tf.contrib.layers.xavier_initializer</span></code>.</p>
<p>Additionally, create an empty list that will contain the initialization operations to be performed at the start of a session.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[481]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Weights and biases</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;h1&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;w_h1&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">N_INPUTS</span><span class="p">,</span> <span class="n">N_HIDDEN_1</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()),</span>
    <span class="s1">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;w_out&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">N_HIDDEN_1</span><span class="p">,</span> <span class="n">N_OUTPUTS</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()),</span>
<span class="p">}</span>
<span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;b1&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;b_1&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">N_HIDDEN_1</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()),</span>
    <span class="s1">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;b_out&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">N_OUTPUTS</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()),</span>
<span class="p">}</span>

<span class="c1"># List for initialization operations</span>
<span class="n">init_ops</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Datasets">
<h3>Datasets<a class="headerlink" href="#Datasets" title="Permalink to this headline">¶</a></h3>
<p>Now let’s use the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API to wrap our task data.</p>
<p>The first step of the setup is that each of the datasets (training, validation, and testing) are turned into their own <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> objects.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[482]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Training dataset</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X_TRAIN</span><span class="p">,</span> <span class="n">Y_TRAIN</span><span class="p">))</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="c1"># Validation dataset</span>
<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X_VAL</span><span class="p">,</span> <span class="n">Y_VAL</span><span class="p">))</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">N_VAL</span><span class="p">)</span>
<span class="c1"># Testing dataset</span>
<span class="n">dataset_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X_TEST</span><span class="p">,</span> <span class="n">Y_TEST</span><span class="p">))</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">N_TEST</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Next, let’s define the iterators for each of the datasets, and then add their initializations to the <code class="docutils literal notranslate"><span class="pre">init_ops</span></code> list.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[483]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Training iterator</span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span>
<span class="c1"># Validation iterator</span>
<span class="n">val_iter</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span>
<span class="c1"># Testing iterator</span>
<span class="n">test_iter</span> <span class="o">=</span> <span class="n">dataset_test</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span>

<span class="c1"># Add the initiatlizations to the init opts</span>
<span class="n">init_ops</span> <span class="o">+=</span> <span class="p">[</span><span class="n">train_iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">val_iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">test_iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>And finally, the interesting part.</p>
<p>Rather than creating separate next elements for the model, the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API has a string handler iterator so we can contextually switch the active <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> object, resulting in different values being used for <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
<p>The way this is done is by defining a <code class="docutils literal notranslate"><span class="pre">tf.placeholder</span></code> variable, which is used first to create a string handler iterator, and later to hold the dataset-indicating string handle. The string handler iterator is what then changes the values of <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>, naturally also supplying them using the <code class="docutils literal notranslate"><span class="pre">get_next</span></code> method.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[484]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># The placeholder variable of type string</span>
<span class="n">handle</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[])</span>
<span class="c1"># Iterator from string handle</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="o">.</span><span class="n">from_string_handle</span><span class="p">(</span>
    <span class="n">handle</span><span class="p">,</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">output_types</span><span class="p">,</span>
    <span class="n">dataset_train</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>

<span class="c1"># x and y that will be used in the graph</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="O'Reilly-Model">
<h3>O’Reilly Model<a class="headerlink" href="#O'Reilly-Model" title="Permalink to this headline">¶</a></h3>
<p>The architecture is the same as before, with one slight change. The output layer no longer has the sigmoid activation, but only because it is baked into the loss function <code class="docutils literal notranslate"><span class="pre">tf.nn.sigmoid_cross_entropy_with_logits</span></code>, which naturally takes in logits.</p>
<p>Note that when instantiating the model, <code class="docutils literal notranslate"><span class="pre">x</span></code> is passed in as the inputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[485]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">oreilly_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="c1"># Reshape for hidden layer</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_INPUTS</span><span class="p">])</span>
    <span class="c1"># Single hidden layer</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;h1&#39;</span><span class="p">]),</span> <span class="n">biases</span><span class="p">[</span><span class="s1">&#39;b1&#39;</span><span class="p">]))</span>
    <span class="c1"># Output layer</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;out&#39;</span><span class="p">]),</span> <span class="n">biases</span><span class="p">[</span><span class="s1">&#39;out&#39;</span><span class="p">])</span>
    <span class="c1"># Reshape for labels</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">STACK</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">,</span> <span class="n">DIMS</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="The-Loss-Function">
<h3>The Loss Function<a class="headerlink" href="#The-Loss-Function" title="Permalink to this headline">¶</a></h3>
<p>For the loss, we’ll use binary cross entropy with vanilla gradient descent.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[486]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">TF_DEVICE</span><span class="p">):</span>
    <span class="c1"># Build the model</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">oreilly_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Ensure y is cast to the same type as logits</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># Define loss and optimizer</span>
    <span class="n">loss_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>

    <span class="c1"># train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss_op</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Metrics">
<h3>Metrics<a class="headerlink" href="#Metrics" title="Permalink to this headline">¶</a></h3>
<p>The last few ops to define before training are the metrics. In particular, O’Reilly defines accuracy to be the fraction of samples where the model was on the correct side of 0.5 for all elements in the outputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[487]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">TF_DEVICE</span><span class="p">):</span>
    <span class="c1"># Define some intermediate nodes</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">rounded_predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    <span class="n">equal_labels_and_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">rounded_predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="c1"># O&#39;Reilly Accuracy</span>
    <span class="n">correct_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">equal_labels_and_preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">accuracy_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float16</span><span class="p">))</span>

    <span class="c1"># Elemental Accuracy</span>
    <span class="n">el_accuracy_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">equal_labels_and_preds</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float16</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="New-Session-Function">
<h3>New Session Function<a class="headerlink" href="#New-Session-Function" title="Permalink to this headline">¶</a></h3>
<p>In the event that we do not want to immediately close sessions, we won’t be using the context handler but will still need to grab new sessions as necessary. So let’s quickly write a function that will properly run <code class="docutils literal notranslate"><span class="pre">sess.close()</span></code> if a previous session exists and then return a new <code class="docutils literal notranslate"><span class="pre">tf.Session</span></code> instance.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[488]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">new_session</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="c1"># Try to close the globally defined session if it isn&#39;t already</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sess</span><span class="o">.</span><span class="n">_closed</span><span class="p">:</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="c1"># If it doesn&#39;t exist, then just pass</span>
    <span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="c1"># Return the new instance</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training-the-Model">
<h3>Training the Model<a class="headerlink" href="#Training-the-Model" title="Permalink to this headline">¶</a></h3>
<p>Let’s define a function that runs the training routine and accepts the number of epochs as the inputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[509]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="c1"># Ensure this is an int</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
    <span class="c1"># Dict with the various metrics we care about</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:[],</span> <span class="s1">&#39;acc&#39;</span><span class="p">:[],</span> <span class="s1">&#39;el_acc&#39;</span><span class="p">:[],</span>
               <span class="s1">&#39;val_loss&#39;</span><span class="p">:[],</span> <span class="s1">&#39;val_acc&#39;</span><span class="p">:[],</span> <span class="s1">&#39;val_el_acc&#39;</span><span class="p">:[]}</span>
    <span class="c1"># Run the initialization ops</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_ops</span><span class="p">)</span>
    <span class="c1"># Define training and validation handlers</span>
    <span class="n">training_handle</span><span class="p">,</span> <span class="n">validation_handle</span><span class="p">,</span> <span class="n">testing_handle</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="p">[</span><span class="n">train_iter</span><span class="o">.</span><span class="n">string_handle</span><span class="p">(),</span>
         <span class="n">val_iter</span><span class="o">.</span><span class="n">string_handle</span><span class="p">(),</span>
         <span class="n">test_iter</span><span class="o">.</span><span class="n">string_handle</span><span class="p">()])</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">,</span> <span class="n">epoch_el_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="n">N_TRAIN</span><span class="p">])</span>
        <span class="c1"># Run the training steps</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_TRAIN</span><span class="p">):</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">epoch_acc</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">epoch_el_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">loss_op</span><span class="p">,</span> <span class="n">accuracy_op</span><span class="p">,</span> <span class="n">el_accuracy_op</span><span class="p">],</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">handle</span><span class="p">:</span> <span class="n">training_handle</span><span class="p">})</span>

        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">el_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">,</span> <span class="n">epoch_el_acc</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Calculate validation accuracy and loss</span>
        <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_el_acc</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">loss_op</span><span class="p">,</span> <span class="n">accuracy_op</span><span class="p">,</span> <span class="n">el_accuracy_op</span><span class="p">],</span>
                                                 <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">handle</span><span class="p">:</span> <span class="n">validation_handle</span><span class="p">})</span>
        <span class="c1"># Record</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="p">[</span><span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">el_acc</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_el_acc</span><span class="p">]):</span>
            <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

        <span class="c1"># Selectively display the epoch number</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">epoch</span> <span class="o">%</span> <span class="p">(</span><span class="n">epochs</span> <span class="o">/</span> <span class="n">N_UPDATES</span><span class="p">)</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Completed epoch </span><span class="si">{0}</span><span class="s2">/</span><span class="si">{1}</span><span class="s2">. Metrics:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
                   <span class="s2">&quot;                     Loss       Accuracy   Elem Accuracy</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
                   <span class="s2">&quot;    Epoch:      </span><span class="si">{2:10.4f}</span><span class="s2">   </span><span class="si">{3:10.4f}</span><span class="s2">   </span><span class="si">{4:10.4f}</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
                   <span class="s2">&quot;    Validation: </span><span class="si">{5:10.4f}</span><span class="s2">   </span><span class="si">{6:10.4f}</span><span class="s2">   </span><span class="si">{7:10.4f}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                      <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">el_acc</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_el_acc</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimization Finished!&quot;</span><span class="p">)</span>
    <span class="c1"># Calculate accuracy for MNIST test images</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing Accuracy:&quot;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy_op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">handle</span><span class="p">:</span> <span class="n">testing_handle</span><span class="p">}))</span>
    <span class="k">return</span> <span class="n">metrics</span>
</pre></div>
</div>
</div>
<p>And now let’s train for <code class="docutils literal notranslate"><span class="pre">EPOCHS</span></code> epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[503]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">new_session</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Completed epoch 1/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.7072       0.0000       0.5708
    Validation:     0.6705       0.0000       0.6260

Completed epoch 11/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.5040       0.0000       0.7998
    Validation:     0.5096       0.0000       0.7998

Completed epoch 21/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4888       0.0000       0.7998
    Validation:     0.5007       0.0000       0.7998

Completed epoch 31/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4834       0.0000       0.7998
    Validation:     0.4981       0.0000       0.7998

Completed epoch 41/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4789       0.0000       0.7998
    Validation:     0.4954       0.0000       0.7998

Completed epoch 50/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4750       0.0000       0.7998
    Validation:     0.4926       0.0000       0.7998

Optimization Finished!
Testing Accuracy: 0.0
CPU times: user 19.1 s, sys: 3.3 s, total: 22.4 s
Wall time: 7.89 s
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Recreating-the-BCE+E-Training-Curves">
<h2>Recreating the BCE+E Training Curves<a class="headerlink" href="#Recreating-the-BCE+E-Training-Curves" title="Permalink to this headline">¶</a></h2>
<p>Just like before, let’s plot the training curves using the metrics we obtained. To do this, let’s borrow the same function we had earlier but make a slight adjustment to it works for plain dictionaries.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[501]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_history</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">history</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="s1">&#39;history&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">array</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training History&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">array</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">EPOCHS</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;500 Epochs&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>This function will now work for both keras history objects and dictionaries.</p>
<div class="section" id="The-Legend">
<h3>The Legend<a class="headerlink" href="#The-Legend" title="Permalink to this headline">¶</a></h3>
<p>One quick thing to go over for the proceeding graphs is the legend. Below are the definitions for them:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">loss</span></code> - Loss for the training set for a particular epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">acc</span></code> - Accuracy as defined by O’Reilly for the training set for a particular epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">el_acc</span></code> - Element-wise accuracy between predictions and labels for the training set for that epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">val_loss</span></code> - Loss for the validation set for a particular epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">val_acc</span></code> - Accuracy as defined by O’Reilly for the validation for a particular epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">val_el_acc</span></code> - Element-wise accuracy between predictions and labels for the validation set for a particular epoch</li>
</ul>
</div>
<div class="section" id="500-Epochs">
<h3>500 Epochs<a class="headerlink" href="#500-Epochs" title="Permalink to this headline">¶</a></h3>
<p>Start the plot for just 500 epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[527]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">new_session</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Completed epoch 1/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.7023       0.0000       0.5130
    Validation:     0.6680       0.0000       0.5752

Completed epoch 101/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4520       0.0000       0.7998
    Validation:     0.4764       0.0000       0.7998

Completed epoch 201/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4025       0.0000       0.8026
    Validation:     0.4413       0.0000       0.8003

Completed epoch 301/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.3497       0.0000       0.8245
    Validation:     0.4038       0.0000       0.8076

Completed epoch 401/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.3009       0.0000       0.8638
    Validation:     0.3681       0.0000       0.8232

Completed epoch 500/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.2599       0.0000       0.8980
    Validation:     0.3371       0.0000       0.8413

Optimization Finished!
Testing Accuracy: 0.0
CPU times: user 3min 9s, sys: 33.4 s, total: 3min 43s
Wall time: 1min 17s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[528]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_history</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.3-BP-Model-in-Tensorflow_62_0.png" src="../_images/notebooks_0.3-BP-Model-in-Tensorflow_62_0.png" />
</div>
</div>
</div>
<div class="section" id="10-x-500-Epochs">
<h3>10 x 500 Epochs<a class="headerlink" href="#10-x-500-Epochs" title="Permalink to this headline">¶</a></h3>
<p>Let’s recreate the same plot shown above for the O’Reilly model when running for ten times as many epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[529]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">new_session</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="o">*</span><span class="n">EPOCHS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Completed epoch 1/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.7112       0.0000       0.5335
    Validation:     0.6719       0.0000       0.5820

Completed epoch 1001/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.1371       0.4000       0.9780
    Validation:     0.2373       0.0200       0.9053

Completed epoch 2001/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0590       0.9700       0.9993
    Validation:     0.1594       0.1000       0.9404

Completed epoch 3001/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0344       1.0000       1.0000
    Validation:     0.1280       0.2000       0.9541

Completed epoch 4001/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0234       1.0000       1.0000
    Validation:     0.1112       0.2000       0.9614

Completed epoch 5000/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0175       1.0000       1.0000
    Validation:     0.1006       0.2400       0.9644

Optimization Finished!
Testing Accuracy: 0.24
CPU times: user 31min 38s, sys: 5min 29s, total: 37min 7s
Wall time: 12min 52s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[530]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_history</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.3-BP-Model-in-Tensorflow_65_0.png" src="../_images/notebooks_0.3-BP-Model-in-Tensorflow_65_0.png" />
</div>
</div>
</div>
<div class="section" id="50-x-500-Epochs">
<h3>50 x 500 Epochs<a class="headerlink" href="#50-x-500-Epochs" title="Permalink to this headline">¶</a></h3>
<p>It looks as though the model is still continuing to learn as shown by the increasing validation accuracy and falling validation loss. So train it for even longer.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[512]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">metrics_1</span> <span class="o">=</span> <span class="n">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="o">*</span><span class="n">EPOCHS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Completed epoch 1/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.7033       0.0000       0.5765
    Validation:     0.6728       0.0000       0.5991

Completed epoch 5001/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0175       1.0000       1.0000
    Validation:     0.1010       0.2000       0.9648

Completed epoch 10001/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0074       1.0000       1.0000
    Validation:     0.0783       0.3000       0.9727

Completed epoch 15001/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0046       1.0000       1.0000
    Validation:     0.0692       0.3401       0.9761

Completed epoch 20001/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0033       1.0000       1.0000
    Validation:     0.0640       0.3401       0.9780

Completed epoch 25000/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0025       1.0000       1.0000
    Validation:     0.0604       0.3601       0.9785

Optimization Finished!
Testing Accuracy: 0.438
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[515]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_history</span><span class="p">(</span><span class="n">metrics_1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.3-BP-Model-in-Tensorflow_68_0.png" src="../_images/notebooks_0.3-BP-Model-in-Tensorflow_68_0.png" />
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="0.3.1-Comparing-Accuracy-Metrics.html" class="btn btn-neutral float-right" title="0.3.1 Comparing Accuracy Metrics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="0.2.1-Iterating-the-BP-Model-on-GPUs.html" class="btn btn-neutral float-left" title="0.2.1 Iterating the BP Model on GPUs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>