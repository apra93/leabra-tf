

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>0.3 BP Model in Tensorflow &mdash; Leabra Tensorflow 0+untagged.81.g9106ca2 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="0.3.1 Comparing Accuracy Metrics" href="0.3.1-Comparing-Accuracy-Metrics.html" />
    <link rel="prev" title="0.2.1 Iterating the BP Model on GPUs" href="0.2.1-Iterating-the-BP-Model-on-GPUs.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Leabra Tensorflow
          

          
          </a>

          
            
            
              <div class="version">
                0+untagged.81.g9106ca2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../release_schedule.html">Release Schedule</a></li>
</ul>
<p class="caption"><span class="caption-text">Tasks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../combinatorics.html">Combinatorial Generalizaton and Interactivity</a></li>
</ul>
<p class="caption"><span class="caption-text">Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../visualization.html">Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">Utility Functions</a></li>
</ul>
<p class="caption"><span class="caption-text">Notebooks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="0.0-Notebook-Template.html">0.0 Leabra-tf Notebook Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1-Designing-the-Combigen-Task.html">0.1 Implementing the Combinatorial Generalization Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.1-Combigen-All-True-Bug-Fix.html">0.1.1 Combigen All-True Bug Fix</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.2-Combigen-Stacks.html">0.1.2 Combigen Stacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1.3-Specifying-the-Number-of-Lines.html">0.1.3 Specifying the Number of Lines</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.2-Running-a-Basic-Model-on-Combigen.html">0.2 Running a Basic Model on Combigen</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.2.1-Iterating-the-BP-Model-on-GPUs.html">0.2.1 Iterating the BP Model on GPUs</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">0.3 BP Model in Tensorflow</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Boilerplate">Boilerplate</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Jupyter-Extensions">Jupyter Extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Imports">Imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Initial-Setup">Initial Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Global-Variables">Global Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Combigen-Task-Variables">Combigen Task Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Data-Parameters">Data Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Datasets">Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Network-Parameters">Network Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Training-Parameters">Training Parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Background">Background</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#The-Combigen-Task">The Combigen Task</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Keras-Implementation">Keras Implementation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#The-Tensorflow-Pipeline">The Tensorflow Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Variables">Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Datasets">Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#O'Reilly-Model">Oâ€™Reilly Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-Loss-Function">The Loss Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Metrics">Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#New-Session-Function">New Session Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Training-the-Model">Training the Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Recreating-the-BCE+E-Training-Curves">Recreating the BCE+E Training Curves</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#The-Legend">The Legend</a></li>
<li class="toctree-l3"><a class="reference internal" href="#500-Epochs">500 Epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#10-x-500-Epochs">10 x 500 Epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#50-x-500-Epochs">50 x 500 Epochs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="0.3.1-Comparing-Accuracy-Metrics.html">0.3.1 Comparing Accuracy Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.4-Exploring-Different-Learning-Rates.html">0.4 Exploring Different Learning Rates</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.4.1-Exploring-Different-Optimizers.html">0.4 Exploring Different Optimizers</a></li>
</ul>
<p class="caption"><span class="caption-text">Project Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://apra93.github.io/leabra-tf/">Home</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apra93/leabra-tf/">Github</a></li>
<li class="toctree-l1"><a class="reference external" href="https://travis-ci.org/apra93/leabra-tf">Travis CI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://codecov.io/gh/apra93/leabra-tf">Codecov</a></li>
<li class="toctree-l1"><a class="reference external" href="https://app.codacy.com/project/apra93/leabra-tf/dashboard">Codacy</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Leabra Tensorflow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>0.3 BP Model in Tensorflow</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/0.3-BP-Model-in-Tensorflow.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="0.3-BP-Model-in-Tensorflow">
<h1>0.3 BP Model in Tensorflow<a class="headerlink" href="#0.3-BP-Model-in-Tensorflow" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="Boilerplate">
<h2>Boilerplate<a class="headerlink" href="#Boilerplate" title="Permalink to this headline">Â¶</a></h2>
<p>The following subsections are largely boilerplate code, so skip around as needed.</p>
<div class="section" id="Jupyter-Extensions">
<h3>Jupyter Extensions<a class="headerlink" href="#Jupyter-Extensions" title="Permalink to this headline">Â¶</a></h3>
<p>Load <a class="reference external" href="https://github.com/rasbt/watermark">watermark</a> to see the state of the machine and environment thatâ€™s running the notebook. To make sense of the options, take a look at the <a class="reference external" href="https://github.com/rasbt/watermark#usage">usage</a> section of the readme.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Load `watermark` extension</span>
<span class="o">%</span><span class="k">load_ext</span> watermark
<span class="c1"># Display the status of the machine and packages. Add more as necessary.</span>
<span class="o">%</span><span class="k">watermark</span> -v -n -m -g -b -t -p numpy,matplotlib,seaborn,tensorflow
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sun Mar 03 2019 01:37:24

CPython 3.6.8
IPython 7.3.0

numpy 1.16.2
matplotlib 3.0.3
seaborn 0.9.0
tensorflow 1.12.0

compiler   : GCC 7.3.0
system     : Linux
release    : 4.4.0-130-generic
machine    : x86_64
processor  : x86_64
CPU cores  : 12
interpreter: 64bit
Git hash   : edd22d45c1c38e765037bf04d03c4caf4494dc66
Git branch : master
</pre></div></div>
</div>
<p>Load <a class="reference external" href="https://ipython.org/ipython-doc/3/config/extensions/autoreload.html">autoreload</a> which will always reload modules marked with <code class="docutils literal notranslate"><span class="pre">%aimport</span></code>.</p>
<p>This behavior can be inverted by running <code class="docutils literal notranslate"><span class="pre">autoreload</span> <span class="pre">2</span></code> which will set everything to be auto-reloaded <em>except</em> for modules marked with <code class="docutils literal notranslate"><span class="pre">%aimport</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Load `autoreload` extension</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="c1"># Set autoreload behavior</span>
<span class="o">%</span><span class="k">autoreload</span> 1
</pre></div>
</div>
</div>
<p>Load <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> in one of the more <code class="docutils literal notranslate"><span class="pre">jupyter</span></code>-friendly <a class="reference external" href="https://ipython.readthedocs.io/en/stable/interactive/plotting.html">rich-output modes</a>. Some options (that may or may not have worked) are <code class="docutils literal notranslate"><span class="pre">inline</span></code>, <code class="docutils literal notranslate"><span class="pre">notebook</span></code>, and <code class="docutils literal notranslate"><span class="pre">gtk</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Set the matplotlib mode</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="section" id="Imports">
<h3>Imports<a class="headerlink" href="#Imports" title="Permalink to this headline">Â¶</a></h3>
<p>Static imports that shouldnâ€™t necessarily change throughout the notebook.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[410]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Standard library imports</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">reduce</span>

<span class="c1"># Third party</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
</div>
<p>Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Task script</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.tasks.combinatorics.combigen
<span class="kn">import</span> <span class="nn">leabratf.tasks.combinatorics.combigen</span> <span class="k">as</span> <span class="nn">cg</span>
<span class="c1"># Visualization for the task</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.visualization.combigen_heatmap
<span class="kn">import</span> <span class="nn">leabratf.visualization.combigen_heatmap</span> <span class="k">as</span> <span class="nn">cgh</span>
<span class="c1"># Utility functions</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.utils
<span class="kn">from</span> <span class="nn">leabratf.utils</span> <span class="k">import</span> <span class="n">setup_logging</span>
<span class="o">%</span><span class="k">aimport</span> leabratf.constants
<span class="kn">from</span> <span class="nn">leabratf.constants</span> <span class="k">import</span> <span class="n">DIR_MODELS</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Initial-Setup">
<h3>Initial Setup<a class="headerlink" href="#Initial-Setup" title="Permalink to this headline">Â¶</a></h3>
<p>Set <a class="reference external" href="https://seaborn.pydata.org/generated/seaborn.set.html">seaborn defaults</a> for matplotlib.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Set up the logger configuration to something more useful than baseline. Creates log files for the different log levels in the <code class="docutils literal notranslate"><span class="pre">logs</span></code> directory.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">logging.yml</span></code> for the exact logging configuration.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Run base logger setup</span>
<span class="c1"># setup_logging()</span>
<span class="c1"># Define a logger object</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;leabratf&#39;</span><span class="p">)</span>
<span class="c1"># Don&#39;t propagate messages</span>
<span class="n">logger</span><span class="o">.</span><span class="n">propagate</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Global-Variables">
<h3>Global Variables<a class="headerlink" href="#Global-Variables" title="Permalink to this headline">Â¶</a></h3>
<div class="section" id="Combigen-Task-Variables">
<h4>Combigen Task Variables<a class="headerlink" href="#Combigen-Task-Variables" title="Permalink to this headline">Â¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Number of slots in a training set</span>
<span class="n">STACK</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1"># Size of each axis in the input array</span>
<span class="n">SIZE</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># Number of axes to use per slot</span>
<span class="n">DIMS</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Data-Parameters">
<h4>Data Parameters<a class="headerlink" href="#Data-Parameters" title="Permalink to this headline">Â¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Number of epochs to train for</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">500</span>
<span class="c1"># Number of samples in the training set</span>
<span class="n">N_TRAIN</span><span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Number of samples in the validation set</span>
<span class="n">N_VAL</span> <span class="o">=</span> <span class="mi">50</span>
<span class="c1"># Number of samples in the testing set</span>
<span class="n">N_TEST</span> <span class="o">=</span> <span class="mi">500</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Datasets">
<h4>Datasets<a class="headerlink" href="#Datasets" title="Permalink to this headline">Â¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Training Data</span>
<span class="n">Y_TRAIN</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">generate_labels</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N_TRAIN</span><span class="p">,</span> <span class="n">stack</span><span class="o">=</span><span class="n">STACK</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">DIMS</span><span class="p">)</span>
<span class="n">X_TRAIN</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">Y_TRAIN</span><span class="p">)</span>
<span class="c1"># Validation Data</span>
<span class="n">Y_VAL</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">generate_labels</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N_VAL</span><span class="p">,</span> <span class="n">stack</span><span class="o">=</span><span class="n">STACK</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">DIMS</span><span class="p">)</span>
<span class="n">X_VAL</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">Y_VAL</span><span class="p">)</span>
<span class="c1"># Testing data</span>
<span class="n">Y_TEST</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">generate_labels</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N_TEST</span><span class="p">,</span> <span class="n">stack</span><span class="o">=</span><span class="n">STACK</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">DIMS</span><span class="p">)</span>
<span class="n">X_TEST</span> <span class="o">=</span> <span class="n">cg</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">Y_TEST</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Network-Parameters">
<h4>Network Parameters<a class="headerlink" href="#Network-Parameters" title="Permalink to this headline">Â¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[79]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Learning rate</span>
<span class="n">ALPHA</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="c1"># Batch size</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Number of parameters in the inputs</span>
<span class="n">N_INPUTS</span> <span class="o">=</span> <span class="n">STACK</span> <span class="o">*</span> <span class="n">SIZE</span> <span class="o">**</span> <span class="n">DIMS</span>
<span class="c1"># Number of hidden units</span>
<span class="n">N_HIDDEN_1</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Number of parameters in the labels</span>
<span class="n">N_OUTPUTS</span> <span class="o">=</span> <span class="n">STACK</span> <span class="o">*</span> <span class="n">SIZE</span> <span class="o">*</span> <span class="n">DIMS</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training-Parameters">
<h4>Training Parameters<a class="headerlink" href="#Training-Parameters" title="Permalink to this headline">Â¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[479]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Number of times to print an update</span>
<span class="n">N_UPDATES</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># Which device to train on</span>
<span class="n">TF_DEVICE</span> <span class="o">=</span> <span class="s1">&#39;/cpu:0&#39;</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="Background">
<h2>Background<a class="headerlink" href="#Background" title="Permalink to this headline">Â¶</a></h2>
<p>This section goes over some of the background information for the notebook using results from previous notebooks. Skip around as needed.</p>
<div class="section" id="The-Combigen-Task">
<h3>The Combigen Task<a class="headerlink" href="#The-Combigen-Task" title="Permalink to this headline">Â¶</a></h3>
<p>Quickly remind ourselves what the task looks like before diving in.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cgh</span><span class="o">.</span><span class="n">visualize_combigen</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.3-BP-Model-in-Tensorflow_32_0.png" src="../_images/notebooks_0.3-BP-Model-in-Tensorflow_32_0.png" />
</div>
</div>
</div>
<div class="section" id="Keras-Implementation">
<h3>Keras Implementation<a class="headerlink" href="#Keras-Implementation" title="Permalink to this headline">Â¶</a></h3>
<p>In nb-0.2.x, the Oâ€™Reilly BP model was implemented in keras with the code having this general structure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bp_model_bce</span><span class="p">(</span><span class="n">hidden_units</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stack</span><span class="o">=</span><span class="n">STACK</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">DIMS</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Builds and returns the model&quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="n">stack</span><span class="o">*</span><span class="n">size</span><span class="o">*</span><span class="n">size</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Initial_reshape&#39;</span><span class="p">))</span>
    <span class="c1"># Single hidden layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Hidden_Layer&#39;</span><span class="p">))</span>
    <span class="c1"># Output layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">stack</span><span class="o">*</span><span class="n">size</span><span class="o">*</span><span class="n">dims</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Output_Layer&#39;</span><span class="p">))</span>
    <span class="c1"># Reshape to match the labels</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="n">stack</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dims</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Output_reshape&#39;</span><span class="p">))</span>

    <span class="c1"># Loss and optimizer to use, along with metrics to track</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
                  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>With the main difference between models tested in nb-0.2.1 being the loss functions. The two most interesting models had the following training curves:</p>
<p><a href="#id3"><span class="problematic" id="id4">|BCE\_SGD|</span></a></p>
<p><a href="#id5"><span class="problematic" id="id6">|MSE\_SGD|</span></a></p>
<p>Some things to note are that the models were trained to 10 times the number of epochs as Oâ€™Reilly did (500). However, a dotted vertical line was added at the 500 epoch mark to make it clear what the modelâ€™s performance would have looked like.</p>
</div>
</div>
<div class="section" id="The-Tensorflow-Pipeline">
<h2>The Tensorflow Pipeline<a class="headerlink" href="#The-Tensorflow-Pipeline" title="Permalink to this headline">Â¶</a></h2>
<p>Using the results of the keras implementation as the benchmark for this model, letâ€™s rewrite the model using pure tensorflow. Letâ€™s start by resetting the graph and then defining the weights and associated biases.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[480]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Cleanup any residual nodes</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="Variables">
<h3>Variables<a class="headerlink" href="#Variables" title="Permalink to this headline">Â¶</a></h3>
<p>Straight forward section where we define the weights and biases. One thing to note is that the weights are initialized using the <code class="docutils literal notranslate"><span class="pre">tf.contrib.layers.xavier_initializer</span></code>.</p>
<p>Additionally, create an empty list that will contain the initialization operations to be performed at the start of a session.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[481]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Weights and biases</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;h1&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;w_h1&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">N_INPUTS</span><span class="p">,</span> <span class="n">N_HIDDEN_1</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()),</span>
    <span class="s1">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;w_out&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">N_HIDDEN_1</span><span class="p">,</span> <span class="n">N_OUTPUTS</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()),</span>
<span class="p">}</span>
<span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;b1&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;b_1&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">N_HIDDEN_1</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()),</span>
    <span class="s1">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;b_out&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">N_OUTPUTS</span><span class="p">],</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()),</span>
<span class="p">}</span>

<span class="c1"># List for initialization operations</span>
<span class="n">init_ops</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Datasets">
<h3>Datasets<a class="headerlink" href="#Datasets" title="Permalink to this headline">Â¶</a></h3>
<p>Now letâ€™s use the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API to wrap our task data.</p>
<p>The first step of the setup is that each of the datasets (training, validation, and testing) are turned into their own <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> objects.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[482]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Training dataset</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X_TRAIN</span><span class="p">,</span> <span class="n">Y_TRAIN</span><span class="p">))</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="c1"># Validation dataset</span>
<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X_VAL</span><span class="p">,</span> <span class="n">Y_VAL</span><span class="p">))</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">N_VAL</span><span class="p">)</span>
<span class="c1"># Testing dataset</span>
<span class="n">dataset_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X_TEST</span><span class="p">,</span> <span class="n">Y_TEST</span><span class="p">))</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">N_TEST</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Next, letâ€™s define the iterators for each of the datasets, and then add their initializations to the <code class="docutils literal notranslate"><span class="pre">init_ops</span></code> list.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[483]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Training iterator</span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span>
<span class="c1"># Validation iterator</span>
<span class="n">val_iter</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span>
<span class="c1"># Testing iterator</span>
<span class="n">test_iter</span> <span class="o">=</span> <span class="n">dataset_test</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span>

<span class="c1"># Add the initiatlizations to the init opts</span>
<span class="n">init_ops</span> <span class="o">+=</span> <span class="p">[</span><span class="n">train_iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">val_iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">test_iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>And finally, the interesting part.</p>
<p>Rather than creating separate next elements for the model, the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API has a string handler iterator so we can contextually switch the active <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> object, resulting in different values being used for <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
<p>The way this is done is by defining a <code class="docutils literal notranslate"><span class="pre">tf.placeholder</span></code> variable, which is used first to create a string handler iterator, and later to hold the dataset-indicating string handle. The string handler iterator is what then changes the values of <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>, naturally also supplying them using the <code class="docutils literal notranslate"><span class="pre">get_next</span></code> method.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[484]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># The placeholder variable of type string</span>
<span class="n">handle</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[])</span>
<span class="c1"># Iterator from string handle</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="o">.</span><span class="n">from_string_handle</span><span class="p">(</span>
    <span class="n">handle</span><span class="p">,</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">output_types</span><span class="p">,</span>
    <span class="n">dataset_train</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>

<span class="c1"># x and y that will be used in the graph</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="O'Reilly-Model">
<h3>Oâ€™Reilly Model<a class="headerlink" href="#O'Reilly-Model" title="Permalink to this headline">Â¶</a></h3>
<p>The architecture is the same as before, with one slight change. The output layer no longer has the sigmoid activation, but only because it is baked into the loss function <code class="docutils literal notranslate"><span class="pre">tf.nn.sigmoid_cross_entropy_with_logits</span></code>, which naturally takes in logits.</p>
<p>Note that when instantiating the model, <code class="docutils literal notranslate"><span class="pre">x</span></code> is passed in as the inputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[485]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">oreilly_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="c1"># Reshape for hidden layer</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_INPUTS</span><span class="p">])</span>
    <span class="c1"># Single hidden layer</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;h1&#39;</span><span class="p">]),</span> <span class="n">biases</span><span class="p">[</span><span class="s1">&#39;b1&#39;</span><span class="p">]))</span>
    <span class="c1"># Output layer</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;out&#39;</span><span class="p">]),</span> <span class="n">biases</span><span class="p">[</span><span class="s1">&#39;out&#39;</span><span class="p">])</span>
    <span class="c1"># Reshape for labels</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">STACK</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">,</span> <span class="n">DIMS</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="The-Loss-Function">
<h3>The Loss Function<a class="headerlink" href="#The-Loss-Function" title="Permalink to this headline">Â¶</a></h3>
<p>For the loss, weâ€™ll use binary cross entropy with vanilla gradient descent.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[486]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">TF_DEVICE</span><span class="p">):</span>
    <span class="c1"># Build the model</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">oreilly_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Ensure y is cast to the same type as logits</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># Define loss and optimizer</span>
    <span class="n">loss_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>

    <span class="c1"># train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss_op</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Metrics">
<h3>Metrics<a class="headerlink" href="#Metrics" title="Permalink to this headline">Â¶</a></h3>
<p>The last few ops to define before training are the metrics. In particular, Oâ€™Reilly defines accuracy to be the fraction of samples where the model was on the correct side of 0.5 for all elements in the outputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[487]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">TF_DEVICE</span><span class="p">):</span>
    <span class="c1"># Define some intermediate nodes</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">rounded_predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    <span class="n">equal_labels_and_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">rounded_predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="c1"># O&#39;Reilly Accuracy</span>
    <span class="n">correct_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">equal_labels_and_preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">accuracy_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float16</span><span class="p">))</span>

    <span class="c1"># Elemental Accuracy</span>
    <span class="n">el_accuracy_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">equal_labels_and_preds</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float16</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="New-Session-Function">
<h3>New Session Function<a class="headerlink" href="#New-Session-Function" title="Permalink to this headline">Â¶</a></h3>
<p>In the event that we do not want to immediately close sessions, we wonâ€™t be using the context handler but will still need to grab new sessions as necessary. So letâ€™s quickly write a function that will properly run <code class="docutils literal notranslate"><span class="pre">sess.close()</span></code> if a previous session exists and then return a new <code class="docutils literal notranslate"><span class="pre">tf.Session</span></code> instance.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[488]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">new_session</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="c1"># Try to close the globally defined session if it isn&#39;t already</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sess</span><span class="o">.</span><span class="n">_closed</span><span class="p">:</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="c1"># If it doesn&#39;t exist, then just pass</span>
    <span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="c1"># Return the new instance</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training-the-Model">
<h3>Training the Model<a class="headerlink" href="#Training-the-Model" title="Permalink to this headline">Â¶</a></h3>
<p>Letâ€™s define a function that runs the training routine and accepts the number of epochs as the inputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[509]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="c1"># Ensure this is an int</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
    <span class="c1"># Dict with the various metrics we care about</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:[],</span> <span class="s1">&#39;acc&#39;</span><span class="p">:[],</span> <span class="s1">&#39;el_acc&#39;</span><span class="p">:[],</span>
               <span class="s1">&#39;val_loss&#39;</span><span class="p">:[],</span> <span class="s1">&#39;val_acc&#39;</span><span class="p">:[],</span> <span class="s1">&#39;val_el_acc&#39;</span><span class="p">:[]}</span>
    <span class="c1"># Run the initialization ops</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_ops</span><span class="p">)</span>
    <span class="c1"># Define training and validation handlers</span>
    <span class="n">training_handle</span><span class="p">,</span> <span class="n">validation_handle</span><span class="p">,</span> <span class="n">testing_handle</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="p">[</span><span class="n">train_iter</span><span class="o">.</span><span class="n">string_handle</span><span class="p">(),</span>
         <span class="n">val_iter</span><span class="o">.</span><span class="n">string_handle</span><span class="p">(),</span>
         <span class="n">test_iter</span><span class="o">.</span><span class="n">string_handle</span><span class="p">()])</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">,</span> <span class="n">epoch_el_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="n">N_TRAIN</span><span class="p">])</span>
        <span class="c1"># Run the training steps</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_TRAIN</span><span class="p">):</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">epoch_acc</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">epoch_el_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">loss_op</span><span class="p">,</span> <span class="n">accuracy_op</span><span class="p">,</span> <span class="n">el_accuracy_op</span><span class="p">],</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">handle</span><span class="p">:</span> <span class="n">training_handle</span><span class="p">})</span>

        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">el_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">,</span> <span class="n">epoch_el_acc</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Calculate validation accuracy and loss</span>
        <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_el_acc</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">loss_op</span><span class="p">,</span> <span class="n">accuracy_op</span><span class="p">,</span> <span class="n">el_accuracy_op</span><span class="p">],</span>
                                                 <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">handle</span><span class="p">:</span> <span class="n">validation_handle</span><span class="p">})</span>
        <span class="c1"># Record</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="p">[</span><span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">el_acc</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_el_acc</span><span class="p">]):</span>
            <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

        <span class="c1"># Selectively display the epoch number</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">epoch</span> <span class="o">%</span> <span class="p">(</span><span class="n">epochs</span> <span class="o">/</span> <span class="n">N_UPDATES</span><span class="p">)</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Completed epoch </span><span class="si">{0}</span><span class="s2">/</span><span class="si">{1}</span><span class="s2">. Metrics:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
                   <span class="s2">&quot;                     Loss       Accuracy   Elem Accuracy</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
                   <span class="s2">&quot;    Epoch:      </span><span class="si">{2:10.4f}</span><span class="s2">   </span><span class="si">{3:10.4f}</span><span class="s2">   </span><span class="si">{4:10.4f}</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
                   <span class="s2">&quot;    Validation: </span><span class="si">{5:10.4f}</span><span class="s2">   </span><span class="si">{6:10.4f}</span><span class="s2">   </span><span class="si">{7:10.4f}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                      <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">el_acc</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_el_acc</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimization Finished!&quot;</span><span class="p">)</span>
    <span class="c1"># Calculate accuracy for MNIST test images</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing Accuracy:&quot;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy_op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">handle</span><span class="p">:</span> <span class="n">testing_handle</span><span class="p">}))</span>
    <span class="k">return</span> <span class="n">metrics</span>
</pre></div>
</div>
</div>
<p>And now letâ€™s train for <code class="docutils literal notranslate"><span class="pre">EPOCHS</span></code> epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[503]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">new_session</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Completed epoch 1/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.7072       0.0000       0.5708
    Validation:     0.6705       0.0000       0.6260

Completed epoch 11/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.5040       0.0000       0.7998
    Validation:     0.5096       0.0000       0.7998

Completed epoch 21/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4888       0.0000       0.7998
    Validation:     0.5007       0.0000       0.7998

Completed epoch 31/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4834       0.0000       0.7998
    Validation:     0.4981       0.0000       0.7998

Completed epoch 41/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4789       0.0000       0.7998
    Validation:     0.4954       0.0000       0.7998

Completed epoch 50/50. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4750       0.0000       0.7998
    Validation:     0.4926       0.0000       0.7998

Optimization Finished!
Testing Accuracy: 0.0
CPU times: user 19.1 s, sys: 3.3 s, total: 22.4 s
Wall time: 7.89 s
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Recreating-the-BCE+E-Training-Curves">
<h2>Recreating the BCE+E Training Curves<a class="headerlink" href="#Recreating-the-BCE+E-Training-Curves" title="Permalink to this headline">Â¶</a></h2>
<p>Just like before, letâ€™s plot the training curves using the metrics we obtained. To do this, letâ€™s borrow the same function we had earlier but make a slight adjustment to it works for plain dictionaries.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[501]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_history</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">history</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="s1">&#39;history&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">array</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training History&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">array</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">EPOCHS</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;500 Epochs&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>This function will now work for both keras history objects and dictionaries.</p>
<div class="section" id="The-Legend">
<h3>The Legend<a class="headerlink" href="#The-Legend" title="Permalink to this headline">Â¶</a></h3>
<p>One quick thing to go over for the proceeding graphs is the legend. Below are the definitions for them:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">loss</span></code> - Loss for the training set for a particular epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">acc</span></code> - Accuracy as defined by Oâ€™Reilly for the training set for a particular epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">el_acc</span></code> - Element-wise accuracy between predictions and labels for the training set for that epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">val_loss</span></code> - Loss for the validation set for a particular epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">val_acc</span></code> - Accuracy as defined by Oâ€™Reilly for the validation for a particular epoch</li>
<li><code class="docutils literal notranslate"><span class="pre">val_el_acc</span></code> - Element-wise accuracy between predictions and labels for the validation set for a particular epoch</li>
</ul>
</div>
<div class="section" id="500-Epochs">
<h3>500 Epochs<a class="headerlink" href="#500-Epochs" title="Permalink to this headline">Â¶</a></h3>
<p>Start the plot for just 500 epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[527]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">new_session</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Completed epoch 1/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.7023       0.0000       0.5130
    Validation:     0.6680       0.0000       0.5752

Completed epoch 101/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4520       0.0000       0.7998
    Validation:     0.4764       0.0000       0.7998

Completed epoch 201/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.4025       0.0000       0.8026
    Validation:     0.4413       0.0000       0.8003

Completed epoch 301/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.3497       0.0000       0.8245
    Validation:     0.4038       0.0000       0.8076

Completed epoch 401/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.3009       0.0000       0.8638
    Validation:     0.3681       0.0000       0.8232

Completed epoch 500/500. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.2599       0.0000       0.8980
    Validation:     0.3371       0.0000       0.8413

Optimization Finished!
Testing Accuracy: 0.0
CPU times: user 3min 9s, sys: 33.4 s, total: 3min 43s
Wall time: 1min 17s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[528]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_history</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.3-BP-Model-in-Tensorflow_62_0.png" src="../_images/notebooks_0.3-BP-Model-in-Tensorflow_62_0.png" />
</div>
</div>
</div>
<div class="section" id="10-x-500-Epochs">
<h3>10 x 500 Epochs<a class="headerlink" href="#10-x-500-Epochs" title="Permalink to this headline">Â¶</a></h3>
<p>Letâ€™s recreate the same plot shown above for the Oâ€™Reilly model when running for ten times as many epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[529]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">new_session</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="o">*</span><span class="n">EPOCHS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Completed epoch 1/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.7112       0.0000       0.5335
    Validation:     0.6719       0.0000       0.5820

Completed epoch 1001/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.1371       0.4000       0.9780
    Validation:     0.2373       0.0200       0.9053

Completed epoch 2001/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0590       0.9700       0.9993
    Validation:     0.1594       0.1000       0.9404

Completed epoch 3001/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0344       1.0000       1.0000
    Validation:     0.1280       0.2000       0.9541

Completed epoch 4001/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0234       1.0000       1.0000
    Validation:     0.1112       0.2000       0.9614

Completed epoch 5000/5000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0175       1.0000       1.0000
    Validation:     0.1006       0.2400       0.9644

Optimization Finished!
Testing Accuracy: 0.24
CPU times: user 31min 38s, sys: 5min 29s, total: 37min 7s
Wall time: 12min 52s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[530]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_history</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.3-BP-Model-in-Tensorflow_65_0.png" src="../_images/notebooks_0.3-BP-Model-in-Tensorflow_65_0.png" />
</div>
</div>
</div>
<div class="section" id="50-x-500-Epochs">
<h3>50 x 500 Epochs<a class="headerlink" href="#50-x-500-Epochs" title="Permalink to this headline">Â¶</a></h3>
<p>It looks as though the model is still continuing to learn as shown by the increasing validation accuracy and falling validation loss. So train it for even longer.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[512]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">metrics_1</span> <span class="o">=</span> <span class="n">train_or_model</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="o">*</span><span class="n">EPOCHS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Completed epoch 1/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.7033       0.0000       0.5765
    Validation:     0.6728       0.0000       0.5991

Completed epoch 5001/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0175       1.0000       1.0000
    Validation:     0.1010       0.2000       0.9648

Completed epoch 10001/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0074       1.0000       1.0000
    Validation:     0.0783       0.3000       0.9727

Completed epoch 15001/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0046       1.0000       1.0000
    Validation:     0.0692       0.3401       0.9761

Completed epoch 20001/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0033       1.0000       1.0000
    Validation:     0.0640       0.3401       0.9780

Completed epoch 25000/25000. Metrics:
                     Loss       Accuracy   Elem Accuracy
    Epoch:          0.0025       1.0000       1.0000
    Validation:     0.0604       0.3601       0.9785

Optimization Finished!
Testing Accuracy: 0.438
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[515]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_history</span><span class="p">(</span><span class="n">metrics_1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_0.3-BP-Model-in-Tensorflow_68_0.png" src="../_images/notebooks_0.3-BP-Model-in-Tensorflow_68_0.png" />
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="0.3.1-Comparing-Accuracy-Metrics.html" class="btn btn-neutral float-right" title="0.3.1 Comparing Accuracy Metrics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="0.2.1-Iterating-the-BP-Model-on-GPUs.html" class="btn btn-neutral float-left" title="0.2.1 Iterating the BP Model on GPUs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>